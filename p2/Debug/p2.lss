
p2.elf:     file format elf32-avr

Sections:
Idx Name          Size      VMA       LMA       File off  Algn
  0 .data         00000028  00800200  0000128c  00001320  2**0
                  CONTENTS, ALLOC, LOAD, DATA
  1 .text         0000128c  00000000  00000000  00000094  2**1
                  CONTENTS, ALLOC, LOAD, READONLY, CODE
  2 .bss          00001409  00800228  00800228  00001348  2**0
                  ALLOC
  3 .comment      00000030  00000000  00000000  00001348  2**0
                  CONTENTS, READONLY
  4 .note.gnu.avr.deviceinfo 00000040  00000000  00000000  00001378  2**2
                  CONTENTS, READONLY
  5 .debug_aranges 00000168  00000000  00000000  000013b8  2**3
                  CONTENTS, READONLY, DEBUGGING
  6 .debug_info   000015f5  00000000  00000000  00001520  2**0
                  CONTENTS, READONLY, DEBUGGING
  7 .debug_abbrev 0000062a  00000000  00000000  00002b15  2**0
                  CONTENTS, READONLY, DEBUGGING
  8 .debug_line   00000ff4  00000000  00000000  0000313f  2**0
                  CONTENTS, READONLY, DEBUGGING
  9 .debug_frame  000002e0  00000000  00000000  00004134  2**2
                  CONTENTS, READONLY, DEBUGGING
 10 .debug_str    00000784  00000000  00000000  00004414  2**0
                  CONTENTS, READONLY, DEBUGGING
 11 .debug_loc    00000eaf  00000000  00000000  00004b98  2**0
                  CONTENTS, READONLY, DEBUGGING
 12 .debug_ranges 000001e0  00000000  00000000  00005a47  2**0
                  CONTENTS, READONLY, DEBUGGING

Disassembly of section .text:

00000000 <__vectors>:
       0:	7e c0       	rjmp	.+252    	; 0xfe <__ctors_end>
       2:	00 00       	nop
       4:	9d c0       	rjmp	.+314    	; 0x140 <__bad_interrupt>
       6:	00 00       	nop
       8:	9b c0       	rjmp	.+310    	; 0x140 <__bad_interrupt>
       a:	00 00       	nop
       c:	99 c0       	rjmp	.+306    	; 0x140 <__bad_interrupt>
       e:	00 00       	nop
      10:	97 c0       	rjmp	.+302    	; 0x140 <__bad_interrupt>
      12:	00 00       	nop
      14:	95 c0       	rjmp	.+298    	; 0x140 <__bad_interrupt>
      16:	00 00       	nop
      18:	93 c0       	rjmp	.+294    	; 0x140 <__bad_interrupt>
      1a:	00 00       	nop
      1c:	91 c0       	rjmp	.+290    	; 0x140 <__bad_interrupt>
      1e:	00 00       	nop
      20:	8f c0       	rjmp	.+286    	; 0x140 <__bad_interrupt>
      22:	00 00       	nop
      24:	8d c0       	rjmp	.+282    	; 0x140 <__bad_interrupt>
      26:	00 00       	nop
      28:	8b c0       	rjmp	.+278    	; 0x140 <__bad_interrupt>
      2a:	00 00       	nop
      2c:	89 c0       	rjmp	.+274    	; 0x140 <__bad_interrupt>
      2e:	00 00       	nop
      30:	87 c0       	rjmp	.+270    	; 0x140 <__bad_interrupt>
      32:	00 00       	nop
      34:	85 c0       	rjmp	.+266    	; 0x140 <__bad_interrupt>
      36:	00 00       	nop
      38:	83 c0       	rjmp	.+262    	; 0x140 <__bad_interrupt>
      3a:	00 00       	nop
      3c:	81 c0       	rjmp	.+258    	; 0x140 <__bad_interrupt>
      3e:	00 00       	nop
      40:	7f c0       	rjmp	.+254    	; 0x140 <__bad_interrupt>
      42:	00 00       	nop
      44:	cc c1       	rjmp	.+920    	; 0x3de <__vector_17>
      46:	00 00       	nop
      48:	7b c0       	rjmp	.+246    	; 0x140 <__bad_interrupt>
      4a:	00 00       	nop
      4c:	79 c0       	rjmp	.+242    	; 0x140 <__bad_interrupt>
      4e:	00 00       	nop
      50:	77 c0       	rjmp	.+238    	; 0x140 <__bad_interrupt>
      52:	00 00       	nop
      54:	75 c0       	rjmp	.+234    	; 0x140 <__bad_interrupt>
      56:	00 00       	nop
      58:	73 c0       	rjmp	.+230    	; 0x140 <__bad_interrupt>
      5a:	00 00       	nop
      5c:	71 c0       	rjmp	.+226    	; 0x140 <__bad_interrupt>
      5e:	00 00       	nop
      60:	6f c0       	rjmp	.+222    	; 0x140 <__bad_interrupt>
      62:	00 00       	nop
      64:	6d c0       	rjmp	.+218    	; 0x140 <__bad_interrupt>
      66:	00 00       	nop
      68:	6b c0       	rjmp	.+214    	; 0x140 <__bad_interrupt>
      6a:	00 00       	nop
      6c:	69 c0       	rjmp	.+210    	; 0x140 <__bad_interrupt>
      6e:	00 00       	nop
      70:	67 c0       	rjmp	.+206    	; 0x140 <__bad_interrupt>
      72:	00 00       	nop
      74:	65 c0       	rjmp	.+202    	; 0x140 <__bad_interrupt>
      76:	00 00       	nop
      78:	63 c0       	rjmp	.+198    	; 0x140 <__bad_interrupt>
      7a:	00 00       	nop
      7c:	61 c0       	rjmp	.+194    	; 0x140 <__bad_interrupt>
      7e:	00 00       	nop
      80:	5f c0       	rjmp	.+190    	; 0x140 <__bad_interrupt>
      82:	00 00       	nop
      84:	5d c0       	rjmp	.+186    	; 0x140 <__bad_interrupt>
      86:	00 00       	nop
      88:	5b c0       	rjmp	.+182    	; 0x140 <__bad_interrupt>
      8a:	00 00       	nop
      8c:	59 c0       	rjmp	.+178    	; 0x140 <__bad_interrupt>
      8e:	00 00       	nop
      90:	57 c0       	rjmp	.+174    	; 0x140 <__bad_interrupt>
      92:	00 00       	nop
      94:	55 c0       	rjmp	.+170    	; 0x140 <__bad_interrupt>
      96:	00 00       	nop
      98:	53 c0       	rjmp	.+166    	; 0x140 <__bad_interrupt>
      9a:	00 00       	nop
      9c:	51 c0       	rjmp	.+162    	; 0x140 <__bad_interrupt>
      9e:	00 00       	nop
      a0:	4f c0       	rjmp	.+158    	; 0x140 <__bad_interrupt>
      a2:	00 00       	nop
      a4:	4d c0       	rjmp	.+154    	; 0x140 <__bad_interrupt>
      a6:	00 00       	nop
      a8:	4b c0       	rjmp	.+150    	; 0x140 <__bad_interrupt>
      aa:	00 00       	nop
      ac:	49 c0       	rjmp	.+146    	; 0x140 <__bad_interrupt>
      ae:	00 00       	nop
      b0:	47 c0       	rjmp	.+142    	; 0x140 <__bad_interrupt>
      b2:	00 00       	nop
      b4:	45 c0       	rjmp	.+138    	; 0x140 <__bad_interrupt>
      b6:	00 00       	nop
      b8:	43 c0       	rjmp	.+134    	; 0x140 <__bad_interrupt>
      ba:	00 00       	nop
      bc:	41 c0       	rjmp	.+130    	; 0x140 <__bad_interrupt>
      be:	00 00       	nop
      c0:	3f c0       	rjmp	.+126    	; 0x140 <__bad_interrupt>
      c2:	00 00       	nop
      c4:	3d c0       	rjmp	.+122    	; 0x140 <__bad_interrupt>
      c6:	00 00       	nop
      c8:	3b c0       	rjmp	.+118    	; 0x140 <__bad_interrupt>
      ca:	00 00       	nop
      cc:	39 c0       	rjmp	.+114    	; 0x140 <__bad_interrupt>
      ce:	00 00       	nop
      d0:	37 c0       	rjmp	.+110    	; 0x140 <__bad_interrupt>
      d2:	00 00       	nop
      d4:	35 c0       	rjmp	.+106    	; 0x140 <__bad_interrupt>
      d6:	00 00       	nop
      d8:	33 c0       	rjmp	.+102    	; 0x140 <__bad_interrupt>
      da:	00 00       	nop
      dc:	31 c0       	rjmp	.+98     	; 0x140 <__bad_interrupt>
      de:	00 00       	nop
      e0:	2f c0       	rjmp	.+94     	; 0x140 <__bad_interrupt>
      e2:	00 00       	nop
      e4:	17 08       	sbc	r1, r7
      e6:	57 05       	cpc	r21, r7
      e8:	17 08       	sbc	r1, r7
      ea:	60 05       	cpc	r22, r0
      ec:	38 06       	cpc	r3, r24
      ee:	7c 06       	cpc	r7, r28
      f0:	97 06       	cpc	r9, r23
      f2:	9b 06       	cpc	r9, r27
      f4:	9d 06       	cpc	r9, r29
      f6:	e0 06       	cpc	r14, r16
      f8:	14 07       	cpc	r17, r20
      fa:	16 07       	cpc	r17, r22
      fc:	8e 07       	cpc	r24, r30

000000fe <__ctors_end>:
      fe:	11 24       	eor	r1, r1
     100:	1f be       	out	0x3f, r1	; 63
     102:	cf ef       	ldi	r28, 0xFF	; 255
     104:	d1 e2       	ldi	r29, 0x21	; 33
     106:	de bf       	out	0x3e, r29	; 62
     108:	cd bf       	out	0x3d, r28	; 61
     10a:	00 e0       	ldi	r16, 0x00	; 0
     10c:	0c bf       	out	0x3c, r16	; 60

0000010e <__do_copy_data>:
     10e:	12 e0       	ldi	r17, 0x02	; 2
     110:	a0 e0       	ldi	r26, 0x00	; 0
     112:	b2 e0       	ldi	r27, 0x02	; 2
     114:	ec e8       	ldi	r30, 0x8C	; 140
     116:	f2 e1       	ldi	r31, 0x12	; 18
     118:	00 e0       	ldi	r16, 0x00	; 0
     11a:	0b bf       	out	0x3b, r16	; 59
     11c:	02 c0       	rjmp	.+4      	; 0x122 <__do_copy_data+0x14>
     11e:	07 90       	elpm	r0, Z+
     120:	0d 92       	st	X+, r0
     122:	a8 32       	cpi	r26, 0x28	; 40
     124:	b1 07       	cpc	r27, r17
     126:	d9 f7       	brne	.-10     	; 0x11e <__do_copy_data+0x10>

00000128 <__do_clear_bss>:
     128:	26 e1       	ldi	r18, 0x16	; 22
     12a:	a8 e2       	ldi	r26, 0x28	; 40
     12c:	b2 e0       	ldi	r27, 0x02	; 2
     12e:	01 c0       	rjmp	.+2      	; 0x132 <.do_clear_bss_start>

00000130 <.do_clear_bss_loop>:
     130:	1d 92       	st	X+, r1

00000132 <.do_clear_bss_start>:
     132:	a1 33       	cpi	r26, 0x31	; 49
     134:	b2 07       	cpc	r27, r18
     136:	e1 f7       	brne	.-8      	; 0x130 <.do_clear_bss_loop>
     138:	0e 94 bf 08 	call	0x117e	; 0x117e <main>
     13c:	0c 94 44 09 	jmp	0x1288	; 0x1288 <_exit>

00000140 <__bad_interrupt>:
     140:	5f cf       	rjmp	.-322    	; 0x0 <__vectors>

00000142 <CSwitch>:
Exit_Kernel:
        /* 
          * This is the "top" half of CSwitch(), generally called by the kernel.
          * Assume I = 0, i.e., all interrupts are disabled.
          */
        SAVECTX
     142:	0f 92       	push	r0
     144:	1f 92       	push	r1
     146:	2f 92       	push	r2
     148:	3f 92       	push	r3
     14a:	4f 92       	push	r4
     14c:	5f 92       	push	r5
     14e:	6f 92       	push	r6
     150:	7f 92       	push	r7
     152:	8f 92       	push	r8
     154:	9f 92       	push	r9
     156:	af 92       	push	r10
     158:	bf 92       	push	r11
     15a:	cf 92       	push	r12
     15c:	df 92       	push	r13
     15e:	ef 92       	push	r14
     160:	ff 92       	push	r15
     162:	0f 93       	push	r16
     164:	1f 93       	push	r17
     166:	2f 93       	push	r18
     168:	3f 93       	push	r19
     16a:	4f 93       	push	r20
     16c:	5f 93       	push	r21
     16e:	6f 93       	push	r22
     170:	7f 93       	push	r23
     172:	8f 93       	push	r24
     174:	9f 93       	push	r25
     176:	af 93       	push	r26
     178:	bf 93       	push	r27
     17a:	cf 93       	push	r28
     17c:	df 93       	push	r29
     17e:	ef 93       	push	r30
     180:	ff 93       	push	r31
     182:	fc b7       	in	r31, 0x3c	; 60
     184:	ff 93       	push	r31
     186:	ff b7       	in	r31, 0x3f	; 63
     188:	ff 93       	push	r31
        /* 
          * Now, we have saved the kernel's context.
          * Save the current H/W stack pointer into KernelSp.
          */
        in   r30, SPL
     18a:	ed b7       	in	r30, 0x3d	; 61
        in   r31, SPH
     18c:	fe b7       	in	r31, 0x3e	; 62
        sts  KernelSp, r30
     18e:	e0 93 27 16 	sts	0x1627, r30
        sts  KernelSp+1, r31
     192:	f0 93 28 16 	sts	0x1628, r31
        /*
          * We are now ready to restore Cp's context, i.e.,
          * switching the H/W stack pointer to CurrentSp.
          */ 
        lds  r30, CurrentSp
     196:	e0 91 21 16 	lds	r30, 0x1621
        lds  r31, CurrentSp+1
     19a:	f0 91 22 16 	lds	r31, 0x1622
        out  SPL, r30
     19e:	ed bf       	out	0x3d, r30	; 61
        out  SPH, r31
     1a0:	fe bf       	out	0x3e, r31	; 62
        /*
          * We are now executing in Cp's stack.
          * Note: at the bottom of the Cp's context is its return address.
          */
        RESTORECTX
     1a2:	ff 91       	pop	r31
     1a4:	ff bf       	out	0x3f, r31	; 63
     1a6:	ff 91       	pop	r31
     1a8:	fc bf       	out	0x3c, r31	; 60
     1aa:	ff 91       	pop	r31
     1ac:	ef 91       	pop	r30
     1ae:	df 91       	pop	r29
     1b0:	cf 91       	pop	r28
     1b2:	bf 91       	pop	r27
     1b4:	af 91       	pop	r26
     1b6:	9f 91       	pop	r25
     1b8:	8f 91       	pop	r24
     1ba:	7f 91       	pop	r23
     1bc:	6f 91       	pop	r22
     1be:	5f 91       	pop	r21
     1c0:	4f 91       	pop	r20
     1c2:	3f 91       	pop	r19
     1c4:	2f 91       	pop	r18
     1c6:	1f 91       	pop	r17
     1c8:	0f 91       	pop	r16
     1ca:	ff 90       	pop	r15
     1cc:	ef 90       	pop	r14
     1ce:	df 90       	pop	r13
     1d0:	cf 90       	pop	r12
     1d2:	bf 90       	pop	r11
     1d4:	af 90       	pop	r10
     1d6:	9f 90       	pop	r9
     1d8:	8f 90       	pop	r8
     1da:	7f 90       	pop	r7
     1dc:	6f 90       	pop	r6
     1de:	5f 90       	pop	r5
     1e0:	4f 90       	pop	r4
     1e2:	3f 90       	pop	r3
     1e4:	2f 90       	pop	r2
     1e6:	1f 90       	pop	r1
     1e8:	0f 90       	pop	r0
        reti         /* re-enable all global interrupts */
     1ea:	18 95       	reti

000001ec <Enter_Kernel>:
Enter_Kernel:   
        /*
          * This is the "bottom" half of CSwitch(). We are still executing in
          * Cp's context.
          */
        SAVECTX
     1ec:	0f 92       	push	r0
     1ee:	1f 92       	push	r1
     1f0:	2f 92       	push	r2
     1f2:	3f 92       	push	r3
     1f4:	4f 92       	push	r4
     1f6:	5f 92       	push	r5
     1f8:	6f 92       	push	r6
     1fa:	7f 92       	push	r7
     1fc:	8f 92       	push	r8
     1fe:	9f 92       	push	r9
     200:	af 92       	push	r10
     202:	bf 92       	push	r11
     204:	cf 92       	push	r12
     206:	df 92       	push	r13
     208:	ef 92       	push	r14
     20a:	ff 92       	push	r15
     20c:	0f 93       	push	r16
     20e:	1f 93       	push	r17
     210:	2f 93       	push	r18
     212:	3f 93       	push	r19
     214:	4f 93       	push	r20
     216:	5f 93       	push	r21
     218:	6f 93       	push	r22
     21a:	7f 93       	push	r23
     21c:	8f 93       	push	r24
     21e:	9f 93       	push	r25
     220:	af 93       	push	r26
     222:	bf 93       	push	r27
     224:	cf 93       	push	r28
     226:	df 93       	push	r29
     228:	ef 93       	push	r30
     22a:	ff 93       	push	r31
     22c:	fc b7       	in	r31, 0x3c	; 60
     22e:	ff 93       	push	r31
     230:	ff b7       	in	r31, 0x3f	; 63
     232:	ff 93       	push	r31
        /* 
          * Now, we have saved the Cp's context.
          * Save the current H/W stack pointer into CurrentSp.
          */
        in   r30, SPL
     234:	ed b7       	in	r30, 0x3d	; 61
        in   r31, SPH
     236:	fe b7       	in	r31, 0x3e	; 62
        sts  CurrentSp, r30
     238:	e0 93 21 16 	sts	0x1621, r30
        sts  CurrentSp+1, r31
     23c:	f0 93 22 16 	sts	0x1622, r31
        /*
          * We are now ready to restore kernel's context, i.e.,
          * switching the H/W stack pointer back to KernelSp.
          */ 
        lds  r30, KernelSp
     240:	e0 91 27 16 	lds	r30, 0x1627
        lds  r31, KernelSp+1
     244:	f0 91 28 16 	lds	r31, 0x1628
        out  SPL, r30
     248:	ed bf       	out	0x3d, r30	; 61
        out  SPH, r31
     24a:	fe bf       	out	0x3e, r31	; 62
        /*
          * We are now executing in kernel's stack.
          */
       RESTORECTX
     24c:	ff 91       	pop	r31
     24e:	ff bf       	out	0x3f, r31	; 63
     250:	ff 91       	pop	r31
     252:	fc bf       	out	0x3c, r31	; 60
     254:	ff 91       	pop	r31
     256:	ef 91       	pop	r30
     258:	df 91       	pop	r29
     25a:	cf 91       	pop	r28
     25c:	bf 91       	pop	r27
     25e:	af 91       	pop	r26
     260:	9f 91       	pop	r25
     262:	8f 91       	pop	r24
     264:	7f 91       	pop	r23
     266:	6f 91       	pop	r22
     268:	5f 91       	pop	r21
     26a:	4f 91       	pop	r20
     26c:	3f 91       	pop	r19
     26e:	2f 91       	pop	r18
     270:	1f 91       	pop	r17
     272:	0f 91       	pop	r16
     274:	ff 90       	pop	r15
     276:	ef 90       	pop	r14
     278:	df 90       	pop	r13
     27a:	cf 90       	pop	r12
     27c:	bf 90       	pop	r11
     27e:	af 90       	pop	r10
     280:	9f 90       	pop	r9
     282:	8f 90       	pop	r8
     284:	7f 90       	pop	r7
     286:	6f 90       	pop	r6
     288:	5f 90       	pop	r5
     28a:	4f 90       	pop	r4
     28c:	3f 90       	pop	r3
     28e:	2f 90       	pop	r2
     290:	1f 90       	pop	r1
     292:	0f 90       	pop	r0
        /* 
          * We are ready to return to the caller of CSwitch() (or Exit_Kernel()).
          * Note: We should NOT re-enable interrupts while kernel is running.
          *         Therefore, we use "ret", and not "reti".
          */
       ret
     294:	08 95       	ret

00000296 <findProcessByPID>:
	
	if(e1 == NULL) 
		return 0;
		
	return e1->count;	
}
     296:	18 16       	cp	r1, r24
     298:	19 06       	cpc	r1, r25
     29a:	84 f5       	brge	.+96     	; 0x2fc <findProcessByPID+0x66>
     29c:	20 91 3a 05 	lds	r18, 0x053A
     2a0:	30 91 3b 05 	lds	r19, 0x053B
     2a4:	28 17       	cp	r18, r24
     2a6:	39 07       	cpc	r19, r25
     2a8:	99 f0       	breq	.+38     	; 0x2d0 <findProcessByPID+0x3a>
     2aa:	21 e0       	ldi	r18, 0x01	; 1
     2ac:	30 e0       	ldi	r19, 0x00	; 0
     2ae:	6e e0       	ldi	r22, 0x0E	; 14
     2b0:	71 e0       	ldi	r23, 0x01	; 1
     2b2:	26 9f       	mul	r18, r22
     2b4:	f0 01       	movw	r30, r0
     2b6:	27 9f       	mul	r18, r23
     2b8:	f0 0d       	add	r31, r0
     2ba:	36 9f       	mul	r19, r22
     2bc:	f0 0d       	add	r31, r0
     2be:	11 24       	eor	r1, r1
     2c0:	e6 5c       	subi	r30, 0xC6	; 198
     2c2:	fa 4f       	sbci	r31, 0xFA	; 250
     2c4:	40 81       	ld	r20, Z
     2c6:	51 81       	ldd	r21, Z+1	; 0x01
     2c8:	48 17       	cp	r20, r24
     2ca:	59 07       	cpc	r21, r25
     2cc:	79 f4       	brne	.+30     	; 0x2ec <findProcessByPID+0x56>
     2ce:	02 c0       	rjmp	.+4      	; 0x2d4 <findProcessByPID+0x3e>
     2d0:	20 e0       	ldi	r18, 0x00	; 0
     2d2:	30 e0       	ldi	r19, 0x00	; 0
     2d4:	4e e0       	ldi	r20, 0x0E	; 14
     2d6:	51 e0       	ldi	r21, 0x01	; 1
     2d8:	24 9f       	mul	r18, r20
     2da:	c0 01       	movw	r24, r0
     2dc:	25 9f       	mul	r18, r21
     2de:	90 0d       	add	r25, r0
     2e0:	34 9f       	mul	r19, r20
     2e2:	90 0d       	add	r25, r0
     2e4:	11 24       	eor	r1, r1
     2e6:	86 5c       	subi	r24, 0xC6	; 198
     2e8:	9a 4f       	sbci	r25, 0xFA	; 250
     2ea:	08 95       	ret
     2ec:	2f 5f       	subi	r18, 0xFF	; 255
     2ee:	3f 4f       	sbci	r19, 0xFF	; 255
     2f0:	20 31       	cpi	r18, 0x10	; 16
     2f2:	31 05       	cpc	r19, r1
     2f4:	f1 f6       	brne	.-68     	; 0x2b2 <findProcessByPID+0x1c>
     2f6:	80 e0       	ldi	r24, 0x00	; 0
     2f8:	90 e0       	ldi	r25, 0x00	; 0
     2fa:	08 95       	ret
     2fc:	80 e0       	ldi	r24, 0x00	; 0
     2fe:	90 e0       	ldi	r25, 0x00	; 0
     300:	08 95       	ret

00000302 <findEventByEventID>:
     302:	00 97       	sbiw	r24, 0x00	; 0
     304:	51 f0       	breq	.+20     	; 0x31a <findEventByEventID+0x18>
     306:	20 91 0a 05 	lds	r18, 0x050A
     30a:	30 91 0b 05 	lds	r19, 0x050B
     30e:	28 17       	cp	r18, r24
     310:	39 07       	cpc	r19, r25
     312:	c1 f0       	breq	.+48     	; 0x344 <findEventByEventID+0x42>
     314:	21 e0       	ldi	r18, 0x01	; 1
     316:	30 e0       	ldi	r19, 0x00	; 0
     318:	06 c0       	rjmp	.+12     	; 0x326 <findEventByEventID+0x24>
     31a:	81 e0       	ldi	r24, 0x01	; 1
     31c:	80 93 20 16 	sts	0x1620, r24
     320:	80 e0       	ldi	r24, 0x00	; 0
     322:	90 e0       	ldi	r25, 0x00	; 0
     324:	08 95       	ret
     326:	f9 01       	movw	r30, r18
     328:	ee 0f       	add	r30, r30
     32a:	ff 1f       	adc	r31, r31
     32c:	e2 0f       	add	r30, r18
     32e:	f3 1f       	adc	r31, r19
     330:	ee 0f       	add	r30, r30
     332:	ff 1f       	adc	r31, r31
     334:	e6 5f       	subi	r30, 0xF6	; 246
     336:	fa 4f       	sbci	r31, 0xFA	; 250
     338:	40 81       	ld	r20, Z
     33a:	51 81       	ldd	r21, Z+1	; 0x01
     33c:	48 17       	cp	r20, r24
     33e:	59 07       	cpc	r21, r25
     340:	69 f4       	brne	.+26     	; 0x35c <findEventByEventID+0x5a>
     342:	02 c0       	rjmp	.+4      	; 0x348 <findEventByEventID+0x46>
     344:	20 e0       	ldi	r18, 0x00	; 0
     346:	30 e0       	ldi	r19, 0x00	; 0
     348:	c9 01       	movw	r24, r18
     34a:	88 0f       	add	r24, r24
     34c:	99 1f       	adc	r25, r25
     34e:	82 0f       	add	r24, r18
     350:	93 1f       	adc	r25, r19
     352:	88 0f       	add	r24, r24
     354:	99 1f       	adc	r25, r25
     356:	86 5f       	subi	r24, 0xF6	; 246
     358:	9a 4f       	sbci	r25, 0xFA	; 250
     35a:	08 95       	ret
     35c:	2f 5f       	subi	r18, 0xFF	; 255
     35e:	3f 4f       	sbci	r19, 0xFF	; 255
     360:	28 30       	cpi	r18, 0x08	; 8
     362:	31 05       	cpc	r19, r1
     364:	01 f7       	brne	.-64     	; 0x326 <findEventByEventID+0x24>
     366:	89 e0       	ldi	r24, 0x09	; 9
     368:	80 93 20 16 	sts	0x1620, r24
     36c:	80 e0       	ldi	r24, 0x00	; 0
     36e:	90 e0       	ldi	r25, 0x00	; 0
     370:	08 95       	ret

00000372 <findMutexByMutexID>:
     372:	00 97       	sbiw	r24, 0x00	; 0
     374:	59 f0       	breq	.+22     	; 0x38c <findMutexByMutexID+0x1a>
     376:	20 91 32 02 	lds	r18, 0x0232
     37a:	30 91 33 02 	lds	r19, 0x0233
     37e:	28 17       	cp	r18, r24
     380:	39 07       	cpc	r19, r25
     382:	b9 f0       	breq	.+46     	; 0x3b2 <findMutexByMutexID+0x40>
     384:	21 e0       	ldi	r18, 0x01	; 1
     386:	30 e0       	ldi	r19, 0x00	; 0
     388:	6b e5       	ldi	r22, 0x5B	; 91
     38a:	06 c0       	rjmp	.+12     	; 0x398 <findMutexByMutexID+0x26>
     38c:	81 e0       	ldi	r24, 0x01	; 1
     38e:	80 93 20 16 	sts	0x1620, r24
     392:	80 e0       	ldi	r24, 0x00	; 0
     394:	90 e0       	ldi	r25, 0x00	; 0
     396:	08 95       	ret
     398:	62 9f       	mul	r22, r18
     39a:	f0 01       	movw	r30, r0
     39c:	63 9f       	mul	r22, r19
     39e:	f0 0d       	add	r31, r0
     3a0:	11 24       	eor	r1, r1
     3a2:	ee 5c       	subi	r30, 0xCE	; 206
     3a4:	fd 4f       	sbci	r31, 0xFD	; 253
     3a6:	40 81       	ld	r20, Z
     3a8:	51 81       	ldd	r21, Z+1	; 0x01
     3aa:	48 17       	cp	r20, r24
     3ac:	59 07       	cpc	r21, r25
     3ae:	61 f4       	brne	.+24     	; 0x3c8 <findMutexByMutexID+0x56>
     3b0:	02 c0       	rjmp	.+4      	; 0x3b6 <findMutexByMutexID+0x44>
     3b2:	20 e0       	ldi	r18, 0x00	; 0
     3b4:	30 e0       	ldi	r19, 0x00	; 0
     3b6:	4b e5       	ldi	r20, 0x5B	; 91
     3b8:	42 9f       	mul	r20, r18
     3ba:	c0 01       	movw	r24, r0
     3bc:	43 9f       	mul	r20, r19
     3be:	90 0d       	add	r25, r0
     3c0:	11 24       	eor	r1, r1
     3c2:	8e 5c       	subi	r24, 0xCE	; 206
     3c4:	9d 4f       	sbci	r25, 0xFD	; 253
     3c6:	08 95       	ret
     3c8:	2f 5f       	subi	r18, 0xFF	; 255
     3ca:	3f 4f       	sbci	r19, 0xFF	; 255
     3cc:	28 30       	cpi	r18, 0x08	; 8
     3ce:	31 05       	cpc	r19, r1
     3d0:	19 f7       	brne	.-58     	; 0x398 <findMutexByMutexID+0x26>
     3d2:	8d e0       	ldi	r24, 0x0D	; 13
     3d4:	80 93 20 16 	sts	0x1620, r24
     3d8:	80 e0       	ldi	r24, 0x00	; 0
     3da:	90 e0       	ldi	r25, 0x00	; 0
     3dc:	08 95       	ret

000003de <__vector_17>:
/*                  ISR FOR HANDLING SLEEP TICKS                        */
/************************************************************************/

//Timer tick ISR
ISR(TIMER1_COMPA_vect)
{
     3de:	1f 92       	push	r1
     3e0:	0f 92       	push	r0
     3e2:	0f b6       	in	r0, 0x3f	; 63
     3e4:	0f 92       	push	r0
     3e6:	11 24       	eor	r1, r1
     3e8:	8f 93       	push	r24
     3ea:	9f 93       	push	r25
	++Tick_Count;
     3ec:	80 91 28 02 	lds	r24, 0x0228
     3f0:	90 91 29 02 	lds	r25, 0x0229
     3f4:	01 96       	adiw	r24, 0x01	; 1
     3f6:	90 93 29 02 	sts	0x0229, r25
     3fa:	80 93 28 02 	sts	0x0228, r24
}
     3fe:	9f 91       	pop	r25
     400:	8f 91       	pop	r24
     402:	0f 90       	pop	r0
     404:	0f be       	out	0x3f, r0	; 63
     406:	0f 90       	pop	r0
     408:	1f 90       	pop	r1
     40a:	18 95       	reti

0000040c <Kernel_Tick_Handler>:
void Kernel_Tick_Handler()
{
	int i;
	
	//No ticks has been issued yet, skipping...
	if(Tick_Count == 0)
     40c:	80 91 28 02 	lds	r24, 0x0228
     410:	90 91 29 02 	lds	r25, 0x0229
     414:	89 2b       	or	r24, r25
     416:	09 f4       	brne	.+2      	; 0x41a <Kernel_Tick_Handler+0xe>
     418:	6f c0       	rjmp	.+222    	; 0x4f8 <Kernel_Tick_Handler+0xec>
     41a:	80 e0       	ldi	r24, 0x00	; 0
     41c:	90 e0       	ldi	r25, 0x00	; 0
		return;
	
	for(i=0; i<MAXTHREAD; i++)
	{
		//Process any active tasks that are sleeping
		if(Process[i].state == SLEEPING)
     41e:	2e e0       	ldi	r18, 0x0E	; 14
     420:	31 e0       	ldi	r19, 0x01	; 1
		{
			//When task_resume is called again, the task will be back into its READY state instead if its sleep ticks expired.
			Process[i].request_arg -= Tick_Count;
			if(Process[i].request_arg <= 0)
			{
				Process[i].last_state = READY;
     422:	61 e0       	ldi	r22, 0x01	; 1
		return;
	
	for(i=0; i<MAXTHREAD; i++)
	{
		//Process any active tasks that are sleeping
		if(Process[i].state == SLEEPING)
     424:	82 9f       	mul	r24, r18
     426:	f0 01       	movw	r30, r0
     428:	83 9f       	mul	r24, r19
     42a:	f0 0d       	add	r31, r0
     42c:	92 9f       	mul	r25, r18
     42e:	f0 0d       	add	r31, r0
     430:	11 24       	eor	r1, r1
     432:	e6 5c       	subi	r30, 0xC6	; 198
     434:	fa 4f       	sbci	r31, 0xFA	; 250
     436:	43 81       	ldd	r20, Z+3	; 0x03
     438:	44 30       	cpi	r20, 0x04	; 4
     43a:	29 f5       	brne	.+74     	; 0x486 <Kernel_Tick_Handler+0x7a>
		{
			//If the current sleeping task's tick count expires, put it back into its READY state
			Process[i].request_arg -= Tick_Count;
     43c:	a0 91 28 02 	lds	r26, 0x0228
     440:	b0 91 29 02 	lds	r27, 0x0229
     444:	82 9f       	mul	r24, r18
     446:	f0 01       	movw	r30, r0
     448:	83 9f       	mul	r24, r19
     44a:	f0 0d       	add	r31, r0
     44c:	92 9f       	mul	r25, r18
     44e:	f0 0d       	add	r31, r0
     450:	11 24       	eor	r1, r1
     452:	e6 5c       	subi	r30, 0xC6	; 198
     454:	fa 4f       	sbci	r31, 0xFA	; 250
     456:	46 81       	ldd	r20, Z+6	; 0x06
     458:	57 81       	ldd	r21, Z+7	; 0x07
     45a:	4a 1b       	sub	r20, r26
     45c:	5b 0b       	sbc	r21, r27
     45e:	57 83       	std	Z+7, r21	; 0x07
     460:	46 83       	std	Z+6, r20	; 0x06
			if(Process[i].request_arg <= 0)
     462:	46 81       	ldd	r20, Z+6	; 0x06
     464:	57 81       	ldd	r21, Z+7	; 0x07
     466:	14 16       	cp	r1, r20
     468:	15 06       	cpc	r1, r21
     46a:	ec f1       	brlt	.+122    	; 0x4e6 <Kernel_Tick_Handler+0xda>
			{
				Process[i].state = READY;
     46c:	82 9f       	mul	r24, r18
     46e:	f0 01       	movw	r30, r0
     470:	83 9f       	mul	r24, r19
     472:	f0 0d       	add	r31, r0
     474:	92 9f       	mul	r25, r18
     476:	f0 0d       	add	r31, r0
     478:	11 24       	eor	r1, r1
     47a:	e6 5c       	subi	r30, 0xC6	; 198
     47c:	fa 4f       	sbci	r31, 0xFA	; 250
     47e:	63 83       	std	Z+3, r22	; 0x03
				Process[i].request_arg = 0;
     480:	17 82       	std	Z+7, r1	; 0x07
     482:	16 82       	std	Z+6, r1	; 0x06
     484:	30 c0       	rjmp	.+96     	; 0x4e6 <Kernel_Tick_Handler+0xda>
			}
		}
		
		//Process any SUSPENDED tasks that were previously sleeping
		else if(Process[i].last_state == SLEEPING)
     486:	82 9f       	mul	r24, r18
     488:	f0 01       	movw	r30, r0
     48a:	83 9f       	mul	r24, r19
     48c:	f0 0d       	add	r31, r0
     48e:	92 9f       	mul	r25, r18
     490:	f0 0d       	add	r31, r0
     492:	11 24       	eor	r1, r1
     494:	e6 5c       	subi	r30, 0xC6	; 198
     496:	fa 4f       	sbci	r31, 0xFA	; 250
     498:	44 81       	ldd	r20, Z+4	; 0x04
     49a:	44 30       	cpi	r20, 0x04	; 4
     49c:	21 f5       	brne	.+72     	; 0x4e6 <Kernel_Tick_Handler+0xda>
		{
			//When task_resume is called again, the task will be back into its READY state instead if its sleep ticks expired.
			Process[i].request_arg -= Tick_Count;
     49e:	a0 91 28 02 	lds	r26, 0x0228
     4a2:	b0 91 29 02 	lds	r27, 0x0229
     4a6:	82 9f       	mul	r24, r18
     4a8:	f0 01       	movw	r30, r0
     4aa:	83 9f       	mul	r24, r19
     4ac:	f0 0d       	add	r31, r0
     4ae:	92 9f       	mul	r25, r18
     4b0:	f0 0d       	add	r31, r0
     4b2:	11 24       	eor	r1, r1
     4b4:	e6 5c       	subi	r30, 0xC6	; 198
     4b6:	fa 4f       	sbci	r31, 0xFA	; 250
     4b8:	46 81       	ldd	r20, Z+6	; 0x06
     4ba:	57 81       	ldd	r21, Z+7	; 0x07
     4bc:	4a 1b       	sub	r20, r26
     4be:	5b 0b       	sbc	r21, r27
     4c0:	57 83       	std	Z+7, r21	; 0x07
     4c2:	46 83       	std	Z+6, r20	; 0x06
			if(Process[i].request_arg <= 0)
     4c4:	46 81       	ldd	r20, Z+6	; 0x06
     4c6:	57 81       	ldd	r21, Z+7	; 0x07
     4c8:	14 16       	cp	r1, r20
     4ca:	15 06       	cpc	r1, r21
     4cc:	64 f0       	brlt	.+24     	; 0x4e6 <Kernel_Tick_Handler+0xda>
			{
				Process[i].last_state = READY;
     4ce:	82 9f       	mul	r24, r18
     4d0:	f0 01       	movw	r30, r0
     4d2:	83 9f       	mul	r24, r19
     4d4:	f0 0d       	add	r31, r0
     4d6:	92 9f       	mul	r25, r18
     4d8:	f0 0d       	add	r31, r0
     4da:	11 24       	eor	r1, r1
     4dc:	e6 5c       	subi	r30, 0xC6	; 198
     4de:	fa 4f       	sbci	r31, 0xFA	; 250
     4e0:	64 83       	std	Z+4, r22	; 0x04
				Process[i].request_arg = 0;
     4e2:	17 82       	std	Z+7, r1	; 0x07
     4e4:	16 82       	std	Z+6, r1	; 0x06
	
	//No ticks has been issued yet, skipping...
	if(Tick_Count == 0)
		return;
	
	for(i=0; i<MAXTHREAD; i++)
     4e6:	01 96       	adiw	r24, 0x01	; 1
     4e8:	80 31       	cpi	r24, 0x10	; 16
     4ea:	91 05       	cpc	r25, r1
     4ec:	09 f0       	breq	.+2      	; 0x4f0 <Kernel_Tick_Handler+0xe4>
     4ee:	9a cf       	rjmp	.-204    	; 0x424 <Kernel_Tick_Handler+0x18>
				Process[i].last_state = READY;
				Process[i].request_arg = 0;
			}
		}
	}
	Tick_Count = 0;
     4f0:	10 92 29 02 	sts	0x0229, r1
     4f4:	10 92 28 02 	sts	0x0228, r1
     4f8:	08 95       	ret

000004fa <Dispatch>:
/*                     KERNEL SCHEDULING FUNCTIONS                      */
/************************************************************************/

/* This internal kernel function is a part of the "scheduler". It chooses the next task to run, i.e., Cp. */
static void Dispatch()
{
     4fa:	cf 93       	push	r28
     4fc:	df 93       	push	r29
     4fe:	20 e1       	ldi	r18, 0x10	; 16
     500:	30 e0       	ldi	r19, 0x00	; 0
	unsigned int i = 0;
	int highest_pri = LOWEST_PRIORITY + 1;
	int highest_pri_index = -1;
     502:	af ef       	ldi	r26, 0xFF	; 255
     504:	bf ef       	ldi	r27, 0xFF	; 255

/* This internal kernel function is a part of the "scheduler". It chooses the next task to run, i.e., Cp. */
static void Dispatch()
{
	unsigned int i = 0;
	int highest_pri = LOWEST_PRIORITY + 1;
     506:	6b e0       	ldi	r22, 0x0B	; 11
     508:	70 e0       	ldi	r23, 0x00	; 0
	{
		//Increment process index
		NextP = (NextP + 1) % MAXTHREAD;
		
		//Select the READY process with the highest priority
		if(Process[NextP].state == READY && Process[NextP].pri < highest_pri)
     50a:	4e e0       	ldi	r20, 0x0E	; 14
     50c:	51 e0       	ldi	r21, 0x01	; 1
	
	//Find the next READY task with the highest priority by iterating through the process list ONCE
	for(i=0; i<MAXTHREAD; i++)
	{
		//Increment process index
		NextP = (NextP + 1) % MAXTHREAD;
     50e:	80 91 30 02 	lds	r24, 0x0230
     512:	90 91 31 02 	lds	r25, 0x0231
     516:	01 96       	adiw	r24, 0x01	; 1
     518:	8f 70       	andi	r24, 0x0F	; 15
     51a:	99 27       	eor	r25, r25
     51c:	90 93 31 02 	sts	0x0231, r25
     520:	80 93 30 02 	sts	0x0230, r24
		
		//Select the READY process with the highest priority
		if(Process[NextP].state == READY && Process[NextP].pri < highest_pri)
     524:	80 91 30 02 	lds	r24, 0x0230
     528:	90 91 31 02 	lds	r25, 0x0231
     52c:	84 9f       	mul	r24, r20
     52e:	f0 01       	movw	r30, r0
     530:	85 9f       	mul	r24, r21
     532:	f0 0d       	add	r31, r0
     534:	94 9f       	mul	r25, r20
     536:	f0 0d       	add	r31, r0
     538:	11 24       	eor	r1, r1
     53a:	e6 5c       	subi	r30, 0xC6	; 198
     53c:	fa 4f       	sbci	r31, 0xFA	; 250
     53e:	83 81       	ldd	r24, Z+3	; 0x03
     540:	81 30       	cpi	r24, 0x01	; 1
     542:	29 f5       	brne	.+74     	; 0x58e <Dispatch+0x94>
     544:	80 91 30 02 	lds	r24, 0x0230
     548:	90 91 31 02 	lds	r25, 0x0231
     54c:	84 9f       	mul	r24, r20
     54e:	f0 01       	movw	r30, r0
     550:	85 9f       	mul	r24, r21
     552:	f0 0d       	add	r31, r0
     554:	94 9f       	mul	r25, r20
     556:	f0 0d       	add	r31, r0
     558:	11 24       	eor	r1, r1
     55a:	e6 5c       	subi	r30, 0xC6	; 198
     55c:	fa 4f       	sbci	r31, 0xFA	; 250
     55e:	82 81       	ldd	r24, Z+2	; 0x02
     560:	90 e0       	ldi	r25, 0x00	; 0
     562:	86 17       	cp	r24, r22
     564:	97 07       	cpc	r25, r23
     566:	9c f4       	brge	.+38     	; 0x58e <Dispatch+0x94>
		{
			highest_pri = Process[NextP].pri;
     568:	80 91 30 02 	lds	r24, 0x0230
     56c:	90 91 31 02 	lds	r25, 0x0231
     570:	84 9f       	mul	r24, r20
     572:	f0 01       	movw	r30, r0
     574:	85 9f       	mul	r24, r21
     576:	f0 0d       	add	r31, r0
     578:	94 9f       	mul	r25, r20
     57a:	f0 0d       	add	r31, r0
     57c:	11 24       	eor	r1, r1
     57e:	e6 5c       	subi	r30, 0xC6	; 198
     580:	fa 4f       	sbci	r31, 0xFA	; 250
     582:	62 81       	ldd	r22, Z+2	; 0x02
     584:	70 e0       	ldi	r23, 0x00	; 0
			highest_pri_index = NextP;
     586:	a0 91 30 02 	lds	r26, 0x0230
     58a:	b0 91 31 02 	lds	r27, 0x0231
     58e:	21 50       	subi	r18, 0x01	; 1
     590:	31 09       	sbc	r19, r1
	unsigned int i = 0;
	int highest_pri = LOWEST_PRIORITY + 1;
	int highest_pri_index = -1;
	
	//Find the next READY task with the highest priority by iterating through the process list ONCE
	for(i=0; i<MAXTHREAD; i++)
     592:	09 f0       	breq	.+2      	; 0x596 <Dispatch+0x9c>
     594:	bc cf       	rjmp	.-136    	; 0x50e <Dispatch+0x14>
			highest_pri_index = NextP;
		}
	}
		
	//When none of the tasks in the process list is ready
	if(highest_pri_index == -1)
     596:	af 3f       	cpi	r26, 0xFF	; 255
     598:	8f ef       	ldi	r24, 0xFF	; 255
     59a:	b8 07       	cpc	r27, r24
     59c:	11 f5       	brne	.+68     	; 0x5e2 <Dispatch+0xe8>
	{
		//We'll temporarily re-enable interrupt in case if one or more task is waiting on events/interrupts or sleeping
		Enable_Interrupt();
     59e:	78 94       	sei
		
		//Looping through the process list until any process becomes ready
		while(Process[NextP].state != READY)
     5a0:	ce e0       	ldi	r28, 0x0E	; 14
     5a2:	d1 e0       	ldi	r29, 0x01	; 1
     5a4:	0c c0       	rjmp	.+24     	; 0x5be <Dispatch+0xc4>
		{
			//Increment process index
			NextP = (NextP + 1) % MAXTHREAD;
     5a6:	80 91 30 02 	lds	r24, 0x0230
     5aa:	90 91 31 02 	lds	r25, 0x0231
     5ae:	01 96       	adiw	r24, 0x01	; 1
     5b0:	8f 70       	andi	r24, 0x0F	; 15
     5b2:	99 27       	eor	r25, r25
     5b4:	90 93 31 02 	sts	0x0231, r25
     5b8:	80 93 30 02 	sts	0x0230, r24
			
			//Check if any timer ticks came in
			Kernel_Tick_Handler();	
     5bc:	27 df       	rcall	.-434    	; 0x40c <Kernel_Tick_Handler>
	{
		//We'll temporarily re-enable interrupt in case if one or more task is waiting on events/interrupts or sleeping
		Enable_Interrupt();
		
		//Looping through the process list until any process becomes ready
		while(Process[NextP].state != READY)
     5be:	80 91 30 02 	lds	r24, 0x0230
     5c2:	90 91 31 02 	lds	r25, 0x0231
     5c6:	8c 9f       	mul	r24, r28
     5c8:	f0 01       	movw	r30, r0
     5ca:	8d 9f       	mul	r24, r29
     5cc:	f0 0d       	add	r31, r0
     5ce:	9c 9f       	mul	r25, r28
     5d0:	f0 0d       	add	r31, r0
     5d2:	11 24       	eor	r1, r1
     5d4:	e6 5c       	subi	r30, 0xC6	; 198
     5d6:	fa 4f       	sbci	r31, 0xFA	; 250
     5d8:	83 81       	ldd	r24, Z+3	; 0x03
     5da:	81 30       	cpi	r24, 0x01	; 1
     5dc:	21 f7       	brne	.-56     	; 0x5a6 <Dispatch+0xac>
			//Check if any timer ticks came in
			Kernel_Tick_Handler();	
		}
		
		//Now that we have a ready task, interrupts must be disabled for the kernel to function properly again.
		Disable_Interrupt();
     5de:	f8 94       	cli
     5e0:	04 c0       	rjmp	.+8      	; 0x5ea <Dispatch+0xf0>
	}
	else
		NextP = highest_pri_index;
     5e2:	b0 93 31 02 	sts	0x0231, r27
     5e6:	a0 93 30 02 	sts	0x0230, r26

	//Load the next selected task's process descriptor into Cp
	Cp = &(Process[NextP]);
     5ea:	20 91 30 02 	lds	r18, 0x0230
     5ee:	30 91 31 02 	lds	r19, 0x0231
     5f2:	8e e0       	ldi	r24, 0x0E	; 14
     5f4:	91 e0       	ldi	r25, 0x01	; 1
     5f6:	28 9f       	mul	r18, r24
     5f8:	f0 01       	movw	r30, r0
     5fa:	29 9f       	mul	r18, r25
     5fc:	f0 0d       	add	r31, r0
     5fe:	38 9f       	mul	r19, r24
     600:	f0 0d       	add	r31, r0
     602:	11 24       	eor	r1, r1
     604:	e6 5c       	subi	r30, 0xC6	; 198
     606:	fa 4f       	sbci	r31, 0xFA	; 250
     608:	f0 93 24 16 	sts	0x1624, r31
     60c:	e0 93 23 16 	sts	0x1623, r30
	CurrentSp = Cp->sp;
     610:	82 85       	ldd	r24, Z+10	; 0x0a
     612:	93 85       	ldd	r25, Z+11	; 0x0b
     614:	90 93 22 16 	sts	0x1622, r25
     618:	80 93 21 16 	sts	0x1621, r24
	Cp->state = RUNNING;
     61c:	82 e0       	ldi	r24, 0x02	; 2
     61e:	83 83       	std	Z+3, r24	; 0x03
}
     620:	df 91       	pop	r29
     622:	cf 91       	pop	r28
     624:	08 95       	ret

00000626 <Kernel_Create_Task>:
/*                   TASK RELATED KERNEL FUNCTIONS                      */
/************************************************************************/

/* Handles all low level operations for creating a new task */
void Kernel_Create_Task(voidfuncptr f, PRIORITY py, int arg)
{
     626:	ef 92       	push	r14
     628:	ff 92       	push	r15
     62a:	0f 93       	push	r16
     62c:	1f 93       	push	r17
     62e:	cf 93       	push	r28
     630:	df 93       	push	r29
     632:	ec 01       	movw	r28, r24
	#ifdef DEBUG
	int counter = 0;
	#endif
	
	//Make sure the system can still have enough resources to create more tasks
	if (Task_Count == MAXTHREAD)
     634:	80 91 2e 02 	lds	r24, 0x022E
     638:	90 91 2f 02 	lds	r25, 0x022F
     63c:	40 97       	sbiw	r24, 0x10	; 16
     63e:	49 f0       	breq	.+18     	; 0x652 <Kernel_Create_Task+0x2c>
		return;
	}

	//Find a dead or empty PD slot to allocate our new task
	for (x = 0; x < MAXTHREAD; x++)
	if (Process[x].state == DEAD) break;
     640:	80 91 3d 05 	lds	r24, 0x053D
     644:	88 23       	and	r24, r24
     646:	d9 f0       	breq	.+54     	; 0x67e <Kernel_Create_Task+0x58>
     648:	21 e0       	ldi	r18, 0x01	; 1
     64a:	30 e0       	ldi	r19, 0x00	; 0
     64c:	ae e0       	ldi	r26, 0x0E	; 14
     64e:	b1 e0       	ldi	r27, 0x01	; 1
     650:	04 c0       	rjmp	.+8      	; 0x65a <Kernel_Create_Task+0x34>
	{
		#ifdef DEBUG
		printf("Task_Create: Failed to create task. The system is at its process threshold.\n");
		#endif
		
		err = MAX_PROCESS_ERR;
     652:	84 e0       	ldi	r24, 0x04	; 4
     654:	80 93 20 16 	sts	0x1620, r24
		return;
     658:	62 c0       	rjmp	.+196    	; 0x71e <Kernel_Create_Task+0xf8>
	}

	//Find a dead or empty PD slot to allocate our new task
	for (x = 0; x < MAXTHREAD; x++)
	if (Process[x].state == DEAD) break;
     65a:	2a 9f       	mul	r18, r26
     65c:	f0 01       	movw	r30, r0
     65e:	2b 9f       	mul	r18, r27
     660:	f0 0d       	add	r31, r0
     662:	3a 9f       	mul	r19, r26
     664:	f0 0d       	add	r31, r0
     666:	11 24       	eor	r1, r1
     668:	e6 5c       	subi	r30, 0xC6	; 198
     66a:	fa 4f       	sbci	r31, 0xFA	; 250
     66c:	93 81       	ldd	r25, Z+3	; 0x03
     66e:	99 23       	and	r25, r25
     670:	41 f0       	breq	.+16     	; 0x682 <Kernel_Create_Task+0x5c>
		err = MAX_PROCESS_ERR;
		return;
	}

	//Find a dead or empty PD slot to allocate our new task
	for (x = 0; x < MAXTHREAD; x++)
     672:	2f 5f       	subi	r18, 0xFF	; 255
     674:	3f 4f       	sbci	r19, 0xFF	; 255
     676:	20 31       	cpi	r18, 0x10	; 16
     678:	31 05       	cpc	r19, r1
     67a:	79 f7       	brne	.-34     	; 0x65a <Kernel_Create_Task+0x34>
     67c:	02 c0       	rjmp	.+4      	; 0x682 <Kernel_Create_Task+0x5c>
	if (Process[x].state == DEAD) break;
     67e:	20 e0       	ldi	r18, 0x00	; 0
     680:	30 e0       	ldi	r19, 0x00	; 0
	
	++Task_Count;
     682:	80 91 2e 02 	lds	r24, 0x022E
     686:	90 91 2f 02 	lds	r25, 0x022F
     68a:	01 96       	adiw	r24, 0x01	; 1
     68c:	90 93 2f 02 	sts	0x022F, r25
     690:	80 93 2e 02 	sts	0x022E, r24
	p = &(Process[x]);
	
	/*The code below was agglomerated from Kernel_Create_Task_At;*/
	
	//Initializing the workspace memory for the new task
	sp = (unsigned char *) &(p->workSpace[WORKSPACE-1]);
     694:	8e e0       	ldi	r24, 0x0E	; 14
     696:	91 e0       	ldi	r25, 0x01	; 1
     698:	28 9f       	mul	r18, r24
     69a:	f0 01       	movw	r30, r0
     69c:	29 9f       	mul	r18, r25
     69e:	f0 0d       	add	r31, r0
     6a0:	38 9f       	mul	r19, r24
     6a2:	f0 0d       	add	r31, r0
     6a4:	11 24       	eor	r1, r1
     6a6:	9f 01       	movw	r18, r30
     6a8:	2b 5b       	subi	r18, 0xBB	; 187
     6aa:	39 4f       	sbci	r19, 0xF9	; 249
	memset(&(p->workSpace),0,WORKSPACE);
     6ac:	8f 01       	movw	r16, r30
     6ae:	0a 5b       	subi	r16, 0xBA	; 186
     6b0:	1a 4f       	sbci	r17, 0xFA	; 250
     6b2:	80 e0       	ldi	r24, 0x00	; 0
     6b4:	91 e0       	ldi	r25, 0x01	; 1
     6b6:	d8 01       	movw	r26, r16
     6b8:	8c 01       	movw	r16, r24
     6ba:	1d 92       	st	X+, r1
     6bc:	01 50       	subi	r16, 0x01	; 1
     6be:	10 40       	sbci	r17, 0x00	; 0
     6c0:	e1 f7       	brne	.-8      	; 0x6ba <Kernel_Create_Task+0x94>

	//Store terminate at the bottom of stack to protect against stack underrun.
	*(unsigned char *)sp-- = ((unsigned int)Task_Terminate) & 0xff;
     6c2:	e6 5c       	subi	r30, 0xC6	; 198
     6c4:	fa 4f       	sbci	r31, 0xFA	; 250
     6c6:	df 01       	movw	r26, r30
     6c8:	a5 5f       	subi	r26, 0xF5	; 245
     6ca:	be 4f       	sbci	r27, 0xFE	; 254
     6cc:	83 e5       	ldi	r24, 0x53	; 83
     6ce:	98 e0       	ldi	r25, 0x08	; 8
     6d0:	8c 93       	st	X, r24
	*(unsigned char *)sp-- = (((unsigned int)Task_Terminate) >> 8) & 0xff;
     6d2:	d9 01       	movw	r26, r18
     6d4:	11 97       	sbiw	r26, 0x01	; 1
     6d6:	9c 93       	st	X, r25
	*(unsigned char *)sp-- = 0x00;
     6d8:	11 97       	sbiw	r26, 0x01	; 1
     6da:	1c 92       	st	X, r1

	//Place return address of function at bottom of stack
	*(unsigned char *)sp-- = ((unsigned int)f) & 0xff;
     6dc:	11 97       	sbiw	r26, 0x01	; 1
     6de:	cc 93       	st	X, r28
	*(unsigned char *)sp-- = (((unsigned int)f) >> 8) & 0xff;
     6e0:	11 97       	sbiw	r26, 0x01	; 1
     6e2:	dc 93       	st	X, r29
	*(unsigned char *)sp-- = 0x00;
     6e4:	11 97       	sbiw	r26, 0x01	; 1
     6e6:	1c 92       	st	X, r1
	 //Place stack pointer at top of stack
	 sp = sp - 34;
	#endif
	
	//Build the process descriptor for the new task
	p->pid = ++Last_PID;
     6e8:	80 91 1a 16 	lds	r24, 0x161A
     6ec:	90 91 1b 16 	lds	r25, 0x161B
     6f0:	01 96       	adiw	r24, 0x01	; 1
     6f2:	90 93 1b 16 	sts	0x161B, r25
     6f6:	80 93 1a 16 	sts	0x161A, r24
     6fa:	91 83       	std	Z+1, r25	; 0x01
     6fc:	80 83       	st	Z, r24
	p->pri = py;
     6fe:	62 83       	std	Z+2, r22	; 0x02
	p->arg = arg;
     700:	51 87       	std	Z+9, r21	; 0x09
     702:	40 87       	std	Z+8, r20	; 0x08
	p->request = NONE;
     704:	15 82       	std	Z+5, r1	; 0x05
	p->state = READY;
     706:	81 e0       	ldi	r24, 0x01	; 1
     708:	83 83       	std	Z+3, r24	; 0x03
	 {
		 *(unsigned char *)sp-- = counter;
	 }
	#else
	 //Place stack pointer at top of stack
	 sp = sp - 34;
     70a:	28 52       	subi	r18, 0x28	; 40
     70c:	31 09       	sbc	r19, r1
	p->pid = ++Last_PID;
	p->pri = py;
	p->arg = arg;
	p->request = NONE;
	p->state = READY;
	p->sp = sp;					/* stack pointer into the "workSpace" */
     70e:	33 87       	std	Z+11, r19	; 0x0b
     710:	22 87       	std	Z+10, r18	; 0x0a
	p->code = f;				/* function to be executed as a task */
     712:	e4 5f       	subi	r30, 0xF4	; 244
     714:	fe 4f       	sbci	r31, 0xFE	; 254
     716:	d1 83       	std	Z+1, r29	; 0x01
     718:	c0 83       	st	Z, r28
	
	//No errors occured
	err = NO_ERR;
     71a:	10 92 20 16 	sts	0x1620, r1
}
     71e:	df 91       	pop	r29
     720:	cf 91       	pop	r28
     722:	1f 91       	pop	r17
     724:	0f 91       	pop	r16
     726:	ff 90       	pop	r15
     728:	ef 90       	pop	r14
     72a:	08 95       	ret

0000072c <Kernel_Create_Event>:
void Kernel_Create_Event(void)
{
	int i;
	
	//Make sure the system's events are not at max
	if(Event_Count >= MAXEVENT)
     72c:	80 91 2c 02 	lds	r24, 0x022C
     730:	90 91 2d 02 	lds	r25, 0x022D
     734:	08 97       	sbiw	r24, 0x08	; 8
     736:	48 f4       	brcc	.+18     	; 0x74a <Kernel_Create_Event+0x1e>
		return;
	}
	
	//Find an uninitialized Event slot
	for(i=0; i<MAXEVENT; i++)
		if(Event[i].id == 0) break;
     738:	80 91 0a 05 	lds	r24, 0x050A
     73c:	90 91 0b 05 	lds	r25, 0x050B
     740:	89 2b       	or	r24, r25
     742:	c9 f0       	breq	.+50     	; 0x776 <Kernel_Create_Event+0x4a>
     744:	81 e0       	ldi	r24, 0x01	; 1
     746:	90 e0       	ldi	r25, 0x00	; 0
     748:	04 c0       	rjmp	.+8      	; 0x752 <Kernel_Create_Event+0x26>
	if(Event_Count >= MAXEVENT)
	{
		#ifdef DEBUG
		printf("Event_Init: Failed to create Event. The system is at its max event threshold.\n");
		#endif
		err = MAX_EVENT_ERR;
     74a:	88 e0       	ldi	r24, 0x08	; 8
     74c:	80 93 20 16 	sts	0x1620, r24
		return;
     750:	08 95       	ret
	}
	
	//Find an uninitialized Event slot
	for(i=0; i<MAXEVENT; i++)
		if(Event[i].id == 0) break;
     752:	fc 01       	movw	r30, r24
     754:	ee 0f       	add	r30, r30
     756:	ff 1f       	adc	r31, r31
     758:	e8 0f       	add	r30, r24
     75a:	f9 1f       	adc	r31, r25
     75c:	ee 0f       	add	r30, r30
     75e:	ff 1f       	adc	r31, r31
     760:	e6 5f       	subi	r30, 0xF6	; 246
     762:	fa 4f       	sbci	r31, 0xFA	; 250
     764:	20 81       	ld	r18, Z
     766:	31 81       	ldd	r19, Z+1	; 0x01
     768:	23 2b       	or	r18, r19
     76a:	39 f0       	breq	.+14     	; 0x77a <Kernel_Create_Event+0x4e>
		err = MAX_EVENT_ERR;
		return;
	}
	
	//Find an uninitialized Event slot
	for(i=0; i<MAXEVENT; i++)
     76c:	01 96       	adiw	r24, 0x01	; 1
     76e:	88 30       	cpi	r24, 0x08	; 8
     770:	91 05       	cpc	r25, r1
     772:	79 f7       	brne	.-34     	; 0x752 <Kernel_Create_Event+0x26>
     774:	02 c0       	rjmp	.+4      	; 0x77a <Kernel_Create_Event+0x4e>
		if(Event[i].id == 0) break;
     776:	80 e0       	ldi	r24, 0x00	; 0
     778:	90 e0       	ldi	r25, 0x00	; 0
	
	//Assign a new unique ID to the event. Note that the smallest valid Event ID is 1.
	Event[i].id = ++Last_EventID;
     77a:	20 91 1e 16 	lds	r18, 0x161E
     77e:	30 91 1f 16 	lds	r19, 0x161F
     782:	2f 5f       	subi	r18, 0xFF	; 255
     784:	3f 4f       	sbci	r19, 0xFF	; 255
     786:	30 93 1f 16 	sts	0x161F, r19
     78a:	20 93 1e 16 	sts	0x161E, r18
     78e:	fc 01       	movw	r30, r24
     790:	ee 0f       	add	r30, r30
     792:	ff 1f       	adc	r31, r31
     794:	df 01       	movw	r26, r30
     796:	a8 0f       	add	r26, r24
     798:	b9 1f       	adc	r27, r25
     79a:	aa 0f       	add	r26, r26
     79c:	bb 1f       	adc	r27, r27
     79e:	a6 5f       	subi	r26, 0xF6	; 246
     7a0:	ba 4f       	sbci	r27, 0xFA	; 250
     7a2:	11 96       	adiw	r26, 0x01	; 1
     7a4:	3c 93       	st	X, r19
     7a6:	2e 93       	st	-X, r18
	Event[i].owner = 0;
     7a8:	fd 01       	movw	r30, r26
     7aa:	13 82       	std	Z+3, r1	; 0x03
     7ac:	12 82       	std	Z+2, r1	; 0x02
	++Event_Count;
     7ae:	80 91 2c 02 	lds	r24, 0x022C
     7b2:	90 91 2d 02 	lds	r25, 0x022D
     7b6:	01 96       	adiw	r24, 0x01	; 1
     7b8:	90 93 2d 02 	sts	0x022D, r25
     7bc:	80 93 2c 02 	sts	0x022C, r24
	err = NO_ERR;
     7c0:	10 92 20 16 	sts	0x1620, r1
     7c4:	08 95       	ret

000007c6 <Kernel_Create_Mutex>:
/************************************************************************/
/*                  MUTEX RELATED KERNEL FUNCTIONS                      */
/************************************************************************/

void Kernel_Create_Mutex(void)
{
     7c6:	cf 93       	push	r28
	int i;
	
	//Make sure the system's mutexes are not at max
	if(Mutex_Count >= MAXMUTEX)
     7c8:	80 91 2a 02 	lds	r24, 0x022A
     7cc:	90 91 2b 02 	lds	r25, 0x022B
     7d0:	08 97       	sbiw	r24, 0x08	; 8
     7d2:	50 f4       	brcc	.+20     	; 0x7e8 <Kernel_Create_Mutex+0x22>
		return;
	}
	
	//Find an uninitialized Mutex slot
	for(i=0; i<MAXMUTEX; i++)
		if(Mutex[i].id == 0) break;
     7d4:	80 91 32 02 	lds	r24, 0x0232
     7d8:	90 91 33 02 	lds	r25, 0x0233
     7dc:	89 2b       	or	r24, r25
     7de:	c9 f0       	breq	.+50     	; 0x812 <Kernel_Create_Mutex+0x4c>
     7e0:	41 e0       	ldi	r20, 0x01	; 1
     7e2:	50 e0       	ldi	r21, 0x00	; 0
     7e4:	2b e5       	ldi	r18, 0x5B	; 91
     7e6:	04 c0       	rjmp	.+8      	; 0x7f0 <Kernel_Create_Mutex+0x2a>
	if(Mutex_Count >= MAXMUTEX)
	{
		#ifdef DEBUG
		printf("Kernel_Create_Mutex: Failed to create Mutex. The system is at its max mutex threshold.\n");
		#endif
		err = MAX_MUTEX_ERR;
     7e8:	8c e0       	ldi	r24, 0x0C	; 12
     7ea:	80 93 20 16 	sts	0x1620, r24
		return;
     7ee:	6b c0       	rjmp	.+214    	; 0x8c6 <Kernel_Create_Mutex+0x100>
	}
	
	//Find an uninitialized Mutex slot
	for(i=0; i<MAXMUTEX; i++)
		if(Mutex[i].id == 0) break;
     7f0:	24 9f       	mul	r18, r20
     7f2:	f0 01       	movw	r30, r0
     7f4:	25 9f       	mul	r18, r21
     7f6:	f0 0d       	add	r31, r0
     7f8:	11 24       	eor	r1, r1
     7fa:	ee 5c       	subi	r30, 0xCE	; 206
     7fc:	fd 4f       	sbci	r31, 0xFD	; 253
     7fe:	80 81       	ld	r24, Z
     800:	91 81       	ldd	r25, Z+1	; 0x01
     802:	89 2b       	or	r24, r25
     804:	41 f0       	breq	.+16     	; 0x816 <Kernel_Create_Mutex+0x50>
		err = MAX_MUTEX_ERR;
		return;
	}
	
	//Find an uninitialized Mutex slot
	for(i=0; i<MAXMUTEX; i++)
     806:	4f 5f       	subi	r20, 0xFF	; 255
     808:	5f 4f       	sbci	r21, 0xFF	; 255
     80a:	48 30       	cpi	r20, 0x08	; 8
     80c:	51 05       	cpc	r21, r1
     80e:	81 f7       	brne	.-32     	; 0x7f0 <Kernel_Create_Mutex+0x2a>
     810:	02 c0       	rjmp	.+4      	; 0x816 <Kernel_Create_Mutex+0x50>
		if(Mutex[i].id == 0) break;
     812:	40 e0       	ldi	r20, 0x00	; 0
     814:	50 e0       	ldi	r21, 0x00	; 0
	
	//Assign a new unique ID to the mutex. Note that the smallest valid mutex ID is 1.
	Mutex[i].id = ++Last_MutexID;
     816:	80 91 25 16 	lds	r24, 0x1625
     81a:	90 91 26 16 	lds	r25, 0x1626
     81e:	01 96       	adiw	r24, 0x01	; 1
     820:	90 93 26 16 	sts	0x1626, r25
     824:	80 93 25 16 	sts	0x1625, r24
     828:	2b e5       	ldi	r18, 0x5B	; 91
     82a:	24 9f       	mul	r18, r20
     82c:	f0 01       	movw	r30, r0
     82e:	25 9f       	mul	r18, r21
     830:	f0 0d       	add	r31, r0
     832:	11 24       	eor	r1, r1
     834:	ee 5c       	subi	r30, 0xCE	; 206
     836:	fd 4f       	sbci	r31, 0xFD	; 253
     838:	91 83       	std	Z+1, r25	; 0x01
     83a:	80 83       	st	Z, r24
	Mutex[i].owner = 0;		// note when mutex's owner is 0, it is free
     83c:	13 82       	std	Z+3, r1	; 0x03
     83e:	12 82       	std	Z+2, r1	; 0x02
	// init priority stack
	for (int j=0; j<MAXTHREAD; j++) {
     840:	80 e0       	ldi	r24, 0x00	; 0
     842:	90 e0       	ldi	r25, 0x00	; 0
		Mutex[i].priority_stack[j] = LOWEST_PRIORITY+1;
     844:	6b e5       	ldi	r22, 0x5B	; 91
     846:	64 9f       	mul	r22, r20
     848:	90 01       	movw	r18, r0
     84a:	65 9f       	mul	r22, r21
     84c:	30 0d       	add	r19, r0
     84e:	11 24       	eor	r1, r1
     850:	df 01       	movw	r26, r30
     852:	cb e0       	ldi	r28, 0x0B	; 11
		Mutex[i].blocked_stack[j] = -1;
     854:	6f ef       	ldi	r22, 0xFF	; 255
     856:	7f ef       	ldi	r23, 0xFF	; 255
	//Assign a new unique ID to the mutex. Note that the smallest valid mutex ID is 1.
	Mutex[i].id = ++Last_MutexID;
	Mutex[i].owner = 0;		// note when mutex's owner is 0, it is free
	// init priority stack
	for (int j=0; j<MAXTHREAD; j++) {
		Mutex[i].priority_stack[j] = LOWEST_PRIORITY+1;
     858:	fd 01       	movw	r30, r26
     85a:	e8 0f       	add	r30, r24
     85c:	f9 1f       	adc	r31, r25
     85e:	c6 a3       	std	Z+38, r28	; 0x26
		Mutex[i].blocked_stack[j] = -1;
     860:	fc 01       	movw	r30, r24
     862:	33 96       	adiw	r30, 0x03	; 3
     864:	ee 0f       	add	r30, r30
     866:	ff 1f       	adc	r31, r31
     868:	e2 0f       	add	r30, r18
     86a:	f3 1f       	adc	r31, r19
     86c:	ee 5c       	subi	r30, 0xCE	; 206
     86e:	fd 4f       	sbci	r31, 0xFD	; 253
     870:	71 83       	std	Z+1, r23	; 0x01
     872:	60 83       	st	Z, r22
		Mutex[i].order[j] = 0;
     874:	fc 01       	movw	r30, r24
     876:	7b 96       	adiw	r30, 0x1b	; 27
     878:	ee 0f       	add	r30, r30
     87a:	ff 1f       	adc	r31, r31
     87c:	e2 0f       	add	r30, r18
     87e:	f3 1f       	adc	r31, r19
     880:	ee 5c       	subi	r30, 0xCE	; 206
     882:	fd 4f       	sbci	r31, 0xFD	; 253
     884:	11 82       	std	Z+1, r1	; 0x01
     886:	10 82       	st	Z, r1
	
	//Assign a new unique ID to the mutex. Note that the smallest valid mutex ID is 1.
	Mutex[i].id = ++Last_MutexID;
	Mutex[i].owner = 0;		// note when mutex's owner is 0, it is free
	// init priority stack
	for (int j=0; j<MAXTHREAD; j++) {
     888:	01 96       	adiw	r24, 0x01	; 1
     88a:	80 31       	cpi	r24, 0x10	; 16
     88c:	91 05       	cpc	r25, r1
     88e:	21 f7       	brne	.-56     	; 0x858 <Kernel_Create_Mutex+0x92>
		Mutex[i].priority_stack[j] = LOWEST_PRIORITY+1;
		Mutex[i].blocked_stack[j] = -1;
		Mutex[i].order[j] = 0;
	}
	Mutex[i].num_of_process = 0;
     890:	2b e5       	ldi	r18, 0x5B	; 91
     892:	24 9f       	mul	r18, r20
     894:	c0 01       	movw	r24, r0
     896:	25 9f       	mul	r18, r21
     898:	90 0d       	add	r25, r0
     89a:	11 24       	eor	r1, r1
     89c:	8e 5c       	subi	r24, 0xCE	; 206
     89e:	9d 4f       	sbci	r25, 0xFD	; 253
     8a0:	fc 01       	movw	r30, r24
     8a2:	ea 5a       	subi	r30, 0xAA	; 170
     8a4:	ff 4f       	sbci	r31, 0xFF	; 255
     8a6:	11 82       	std	Z+1, r1	; 0x01
     8a8:	10 82       	st	Z, r1
	Mutex[i].total_num = 0;
     8aa:	32 96       	adiw	r30, 0x02	; 2
     8ac:	11 82       	std	Z+1, r1	; 0x01
     8ae:	10 82       	st	Z, r1
	++Mutex_Count;
     8b0:	80 91 2a 02 	lds	r24, 0x022A
     8b4:	90 91 2b 02 	lds	r25, 0x022B
     8b8:	01 96       	adiw	r24, 0x01	; 1
     8ba:	90 93 2b 02 	sts	0x022B, r25
     8be:	80 93 2a 02 	sts	0x022A, r24
	err = NO_ERR;
     8c2:	10 92 20 16 	sts	0x1620, r1
	
	#ifdef DEBUG
	printf("Kernel_Create_Mutex: Created Mutex %d!\n", Last_MutexID);
	#endif
}
     8c6:	cf 91       	pop	r28
     8c8:	08 95       	ret

000008ca <Timer_init>:
void Timer_init()
{
	/*Timer1 is configured for the task*/
	
	//Use Prescaler = 256
	TCCR1B |= (1<<CS12);
     8ca:	e1 e8       	ldi	r30, 0x81	; 129
     8cc:	f0 e0       	ldi	r31, 0x00	; 0
     8ce:	80 81       	ld	r24, Z
     8d0:	84 60       	ori	r24, 0x04	; 4
     8d2:	80 83       	st	Z, r24
	TCCR1B &= ~((1<<CS11)|(1<<CS10));
     8d4:	80 81       	ld	r24, Z
     8d6:	8c 7f       	andi	r24, 0xFC	; 252
     8d8:	80 83       	st	Z, r24
	
	//Use CTC mode (mode 4)
	TCCR1B |= (1<<WGM12);
     8da:	80 81       	ld	r24, Z
     8dc:	88 60       	ori	r24, 0x08	; 8
     8de:	80 83       	st	Z, r24
	TCCR1B &= ~((1<<WGM13)|(1<<WGM11)|(1<<WGM10));
     8e0:	80 81       	ld	r24, Z
     8e2:	8c 7e       	andi	r24, 0xEC	; 236
     8e4:	80 83       	st	Z, r24
	
	OCR1A = TICK_LENG;			//Set timer top comparison value to ~10ms
     8e6:	81 e7       	ldi	r24, 0x71	; 113
     8e8:	92 e0       	ldi	r25, 0x02	; 2
     8ea:	90 93 89 00 	sts	0x0089, r25
     8ee:	80 93 88 00 	sts	0x0088, r24
	TCNT1 = 0;					//Load initial value for timer
     8f2:	10 92 85 00 	sts	0x0085, r1
     8f6:	10 92 84 00 	sts	0x0084, r1
	TIMSK1 |= (1<<OCIE1A);      //enable match for OCR1A interrupt
     8fa:	ef e6       	ldi	r30, 0x6F	; 111
     8fc:	f0 e0       	ldi	r31, 0x00	; 0
     8fe:	80 81       	ld	r24, Z
     900:	82 60       	ori	r24, 0x02	; 2
     902:	80 83       	st	Z, r24
     904:	08 95       	ret

00000906 <OS_Init>:
/*This function initializes the RTOS and must be called before any othersystem calls.*/
void OS_Init()
{
	int x;
	
	Task_Count = 0;
     906:	10 92 2f 02 	sts	0x022F, r1
     90a:	10 92 2e 02 	sts	0x022E, r1
	Event_Count = 0;
     90e:	10 92 2d 02 	sts	0x022D, r1
     912:	10 92 2c 02 	sts	0x022C, r1
	KernelActive = 0;
     916:	10 92 1d 16 	sts	0x161D, r1
     91a:	10 92 1c 16 	sts	0x161C, r1
	Tick_Count = 0;
     91e:	10 92 29 02 	sts	0x0229, r1
     922:	10 92 28 02 	sts	0x0228, r1
	NextP = 0;
     926:	10 92 31 02 	sts	0x0231, r1
     92a:	10 92 30 02 	sts	0x0230, r1
	Last_PID = 0;
     92e:	10 92 1b 16 	sts	0x161B, r1
     932:	10 92 1a 16 	sts	0x161A, r1
	Last_EventID = 0;
     936:	10 92 1f 16 	sts	0x161F, r1
     93a:	10 92 1e 16 	sts	0x161E, r1
	Last_MutexID = 0;
     93e:	10 92 26 16 	sts	0x1626, r1
     942:	10 92 25 16 	sts	0x1625, r1
	err = NO_ERR;
     946:	10 92 20 16 	sts	0x1620, r1
	
	//Clear and initialize the memory used for tasks
	memset(Process, 0, MAXTHREAD*sizeof(PD));
     94a:	80 ee       	ldi	r24, 0xE0	; 224
     94c:	90 e1       	ldi	r25, 0x10	; 16
     94e:	ea e3       	ldi	r30, 0x3A	; 58
     950:	f5 e0       	ldi	r31, 0x05	; 5
     952:	df 01       	movw	r26, r30
     954:	9c 01       	movw	r18, r24
     956:	1d 92       	st	X+, r1
     958:	21 50       	subi	r18, 0x01	; 1
     95a:	30 40       	sbci	r19, 0x00	; 0
     95c:	e1 f7       	brne	.-8      	; 0x956 <OS_Init+0x50>
	for (x = 0; x < MAXTHREAD; x++) {
     95e:	80 e0       	ldi	r24, 0x00	; 0
     960:	90 e0       	ldi	r25, 0x00	; 0
		Process[x].state = DEAD;
     962:	2e e0       	ldi	r18, 0x0E	; 14
     964:	31 e0       	ldi	r19, 0x01	; 1
     966:	82 9f       	mul	r24, r18
     968:	f0 01       	movw	r30, r0
     96a:	83 9f       	mul	r24, r19
     96c:	f0 0d       	add	r31, r0
     96e:	92 9f       	mul	r25, r18
     970:	f0 0d       	add	r31, r0
     972:	11 24       	eor	r1, r1
     974:	e6 5c       	subi	r30, 0xC6	; 198
     976:	fa 4f       	sbci	r31, 0xFA	; 250
     978:	13 82       	std	Z+3, r1	; 0x03
	Last_MutexID = 0;
	err = NO_ERR;
	
	//Clear and initialize the memory used for tasks
	memset(Process, 0, MAXTHREAD*sizeof(PD));
	for (x = 0; x < MAXTHREAD; x++) {
     97a:	01 96       	adiw	r24, 0x01	; 1
     97c:	80 31       	cpi	r24, 0x10	; 16
     97e:	91 05       	cpc	r25, r1
     980:	91 f7       	brne	.-28     	; 0x966 <OS_Init+0x60>
		Process[x].state = DEAD;
	}
	
	//Clear and initialize the memory used for Events
	memset(Event, 0, MAXEVENT*sizeof(EVENT_TYPE));
     982:	80 e3       	ldi	r24, 0x30	; 48
     984:	ea e0       	ldi	r30, 0x0A	; 10
     986:	f5 e0       	ldi	r31, 0x05	; 5
     988:	df 01       	movw	r26, r30
     98a:	1d 92       	st	X+, r1
     98c:	8a 95       	dec	r24
     98e:	e9 f7       	brne	.-6      	; 0x98a <OS_Init+0x84>
	for (x = 0; x < MAXEVENT; x++) {
     990:	80 e0       	ldi	r24, 0x00	; 0
     992:	90 e0       	ldi	r25, 0x00	; 0
		Event[x].id = 0;
     994:	fc 01       	movw	r30, r24
     996:	ee 0f       	add	r30, r30
     998:	ff 1f       	adc	r31, r31
     99a:	e8 0f       	add	r30, r24
     99c:	f9 1f       	adc	r31, r25
     99e:	ee 0f       	add	r30, r30
     9a0:	ff 1f       	adc	r31, r31
     9a2:	e6 5f       	subi	r30, 0xF6	; 246
     9a4:	fa 4f       	sbci	r31, 0xFA	; 250
     9a6:	11 82       	std	Z+1, r1	; 0x01
     9a8:	10 82       	st	Z, r1
		Process[x].state = DEAD;
	}
	
	//Clear and initialize the memory used for Events
	memset(Event, 0, MAXEVENT*sizeof(EVENT_TYPE));
	for (x = 0; x < MAXEVENT; x++) {
     9aa:	01 96       	adiw	r24, 0x01	; 1
     9ac:	88 30       	cpi	r24, 0x08	; 8
     9ae:	91 05       	cpc	r25, r1
     9b0:	89 f7       	brne	.-30     	; 0x994 <OS_Init+0x8e>
		Event[x].id = 0;
	}
	
	//Clear and initialize the memory used for Mutex
	memset(Mutex, 0, MAXMUTEX*sizeof(MUTEX_TYPE));
     9b2:	88 ed       	ldi	r24, 0xD8	; 216
     9b4:	92 e0       	ldi	r25, 0x02	; 2
     9b6:	e2 e3       	ldi	r30, 0x32	; 50
     9b8:	f2 e0       	ldi	r31, 0x02	; 2
     9ba:	df 01       	movw	r26, r30
     9bc:	9c 01       	movw	r18, r24
     9be:	1d 92       	st	X+, r1
     9c0:	21 50       	subi	r18, 0x01	; 1
     9c2:	30 40       	sbci	r19, 0x00	; 0
     9c4:	e1 f7       	brne	.-8      	; 0x9be <OS_Init+0xb8>
	for (x = 0; x < MAXMUTEX; x++) {
     9c6:	80 e0       	ldi	r24, 0x00	; 0
     9c8:	90 e0       	ldi	r25, 0x00	; 0
		Event[x].id = 0;
     9ca:	fc 01       	movw	r30, r24
     9cc:	ee 0f       	add	r30, r30
     9ce:	ff 1f       	adc	r31, r31
     9d0:	e8 0f       	add	r30, r24
     9d2:	f9 1f       	adc	r31, r25
     9d4:	ee 0f       	add	r30, r30
     9d6:	ff 1f       	adc	r31, r31
     9d8:	e6 5f       	subi	r30, 0xF6	; 246
     9da:	fa 4f       	sbci	r31, 0xFA	; 250
     9dc:	11 82       	std	Z+1, r1	; 0x01
     9de:	10 82       	st	Z, r1
		Event[x].id = 0;
	}
	
	//Clear and initialize the memory used for Mutex
	memset(Mutex, 0, MAXMUTEX*sizeof(MUTEX_TYPE));
	for (x = 0; x < MAXMUTEX; x++) {
     9e0:	01 96       	adiw	r24, 0x01	; 1
     9e2:	88 30       	cpi	r24, 0x08	; 8
     9e4:	91 05       	cpc	r25, r1
     9e6:	89 f7       	brne	.-30     	; 0x9ca <OS_Init+0xc4>
	}
	
	#ifdef DEBUG
	printf("OS initialized!\n");
	#endif
}
     9e8:	08 95       	ret

000009ea <OS_Start>:

/* This function starts the RTOS after creating a few tasks.*/
void OS_Start()
{
     9ea:	2f 92       	push	r2
     9ec:	3f 92       	push	r3
     9ee:	4f 92       	push	r4
     9f0:	5f 92       	push	r5
     9f2:	6f 92       	push	r6
     9f4:	7f 92       	push	r7
     9f6:	8f 92       	push	r8
     9f8:	9f 92       	push	r9
     9fa:	af 92       	push	r10
     9fc:	bf 92       	push	r11
     9fe:	cf 92       	push	r12
     a00:	df 92       	push	r13
     a02:	ef 92       	push	r14
     a04:	ff 92       	push	r15
     a06:	0f 93       	push	r16
     a08:	1f 93       	push	r17
     a0a:	cf 93       	push	r28
     a0c:	df 93       	push	r29
	if ( (! KernelActive) && (Task_Count > 0))
     a0e:	80 91 1c 16 	lds	r24, 0x161C
     a12:	90 91 1d 16 	lds	r25, 0x161D
     a16:	89 2b       	or	r24, r25
     a18:	09 f0       	breq	.+2      	; 0xa1c <OS_Start+0x32>
     a1a:	0f c3       	rjmp	.+1566   	; 0x103a <OS_Start+0x650>
     a1c:	80 91 2e 02 	lds	r24, 0x022E
     a20:	90 91 2f 02 	lds	r25, 0x022F
     a24:	89 2b       	or	r24, r25
     a26:	09 f4       	brne	.+2      	; 0xa2a <OS_Start+0x40>
     a28:	08 c3       	rjmp	.+1552   	; 0x103a <OS_Start+0x650>
	{
		Disable_Interrupt();
     a2a:	f8 94       	cli
		
		/* we may have to initialize the interrupt vector for Enter_Kernel() here. */
			/* here we go...  */
		KernelActive = 1;
     a2c:	81 e0       	ldi	r24, 0x01	; 1
     a2e:	90 e0       	ldi	r25, 0x00	; 0
     a30:	90 93 1d 16 	sts	0x161D, r25
     a34:	80 93 1c 16 	sts	0x161C, r24
		
		/*Initialize and start Timer needed for sleep*/
		Timer_init();
     a38:	48 df       	rcall	.-368    	; 0x8ca <Timer_init>
  *
  * This is the main loop of our kernel, called by OS_Start().
  */
static void Next_Kernel_Request() 
{
	Dispatch();	//Select an initial task to run
     a3a:	5f dd       	rcall	.-1346   	; 0x4fa <Dispatch>
			Dispatch();
			break;
       
			//Invalid request code, just ignore
			default:
				err = INVALID_KERNET_REQUEST_ERR;
     a3c:	68 94       	set
     a3e:	55 24       	eor	r5, r5
     a40:	51 f8       	bld	r5, 1
			//Does this need dispatch under any circumstances?
			break;
		   
			case YIELD:
			case NONE:					// NONE could be caused by a timer interrupt
			Cp->state = READY;
     a42:	99 24       	eor	r9, r9
     a44:	93 94       	inc	r9
	} else if (m->num_of_process > 0) {
		// there are tasks waiting on the mutex
		// deque the task with highest priority
		PID p_dequeue = 0;
		unsigned int temp_order = m->total_num + 1;
		PRIORITY temp_pri = LOWEST_PRIORITY + 1;
     a46:	0f 2e       	mov	r0, r31
     a48:	fb e0       	ldi	r31, 0x0B	; 11
     a4a:	8f 2e       	mov	r8, r31
     a4c:	f0 2d       	mov	r31, r0
	} else {
		Cp->state = WAIT_MUTEX;								//put cp into state wait mutex
		//enqueue cp to stack
		++(m->num_of_process);
		++(m->total_num);
		for (int i=0; i<MAXTHREAD; i++) {
     a4e:	77 24       	eor	r7, r7
     a50:	73 94       	inc	r7
     a52:	61 2c       	mov	r6, r1
		return;
	}
	
	//Ensure the task is not currently owning a mutex
	for(int i=0; i<MAXMUTEX; i++) {
		if (Mutex[i].owner == p->pid) {
     a54:	0f 2e       	mov	r0, r31
     a56:	fb e5       	ldi	r31, 0x5B	; 91
     a58:	cf 2e       	mov	r12, r31
     a5a:	f0 2d       	mov	r31, r0
		if (Mutex[index].owner == Cp->pid) {
			// it owns a mutex unlock the mutex
			if (Mutex[index].num_of_process > 0) {
				printf("something is waiting\n");
				// if there are other process waiting on the mutex
				PID p_dequeue = 0;
     a5c:	41 2c       	mov	r4, r1
     a5e:	31 2c       	mov	r3, r1
	//After OS initialization, THIS WILL BE KERNEL'S MAIN LOOP!
	//NOTE: When another task makes a syscall and enters the loop, it's still in the RUNNING state!
	while(1) 
	{
		//Clears the process' request fields
		Cp->request = NONE;
     a60:	e0 91 23 16 	lds	r30, 0x1623
     a64:	f0 91 24 16 	lds	r31, 0x1624
     a68:	15 82       	std	Z+5, r1	; 0x05
		//Cp->request_arg is not reset, because task_sleep uses it to keep track of remaining ticks

		//Load the current task's stack pointer and switch to its context
		CurrentSp = Cp->sp;
     a6a:	82 85       	ldd	r24, Z+10	; 0x0a
     a6c:	93 85       	ldd	r25, Z+11	; 0x0b
     a6e:	90 93 22 16 	sts	0x1622, r25
     a72:	80 93 21 16 	sts	0x1621, r24
		Exit_Kernel();
     a76:	65 db       	rcall	.-2358   	; 0x142 <CSwitch>

		/* if this task makes a system call, it will return to here! */

		//Save the current task's stack pointer and proceed to handle its request
		Cp->sp = CurrentSp;
     a78:	e0 91 23 16 	lds	r30, 0x1623
     a7c:	f0 91 24 16 	lds	r31, 0x1624
     a80:	80 91 21 16 	lds	r24, 0x1621
     a84:	90 91 22 16 	lds	r25, 0x1622
     a88:	93 87       	std	Z+11, r25	; 0x0b
     a8a:	82 87       	std	Z+10, r24	; 0x0a
		
		//Check if any timer ticks came in
		Kernel_Tick_Handler();
     a8c:	bf dc       	rcall	.-1666   	; 0x40c <Kernel_Tick_Handler>

		switch(Cp->request)
     a8e:	c0 91 23 16 	lds	r28, 0x1623
     a92:	d0 91 24 16 	lds	r29, 0x1624
     a96:	8d 81       	ldd	r24, Y+5	; 0x05
     a98:	90 e0       	ldi	r25, 0x00	; 0
     a9a:	8d 30       	cpi	r24, 0x0D	; 13
     a9c:	91 05       	cpc	r25, r1
     a9e:	08 f0       	brcs	.+2      	; 0xaa2 <OS_Start+0xb8>
     aa0:	c9 c2       	rjmp	.+1426   	; 0x1034 <OS_Start+0x64a>
     aa2:	fc 01       	movw	r30, r24
     aa4:	88 27       	eor	r24, r24
     aa6:	ee 58       	subi	r30, 0x8E	; 142
     aa8:	ff 4f       	sbci	r31, 0xFF	; 255
     aaa:	8f 4f       	sbci	r24, 0xFF	; 255
     aac:	b5 c3       	rjmp	.+1898   	; 0x1218 <__tablejump2__>
		{
			case CREATE_T:
			Kernel_Create_Task(Cp->code, Cp->pri, Cp->arg);
     aae:	48 85       	ldd	r20, Y+8	; 0x08
     ab0:	59 85       	ldd	r21, Y+9	; 0x09
     ab2:	6a 81       	ldd	r22, Y+2	; 0x02
     ab4:	c4 5f       	subi	r28, 0xF4	; 244
     ab6:	de 4f       	sbci	r29, 0xFE	; 254
     ab8:	88 81       	ld	r24, Y
     aba:	99 81       	ldd	r25, Y+1	; 0x01
     abc:	b4 dd       	rcall	.-1176   	; 0x626 <Kernel_Create_Task>
     abe:	d0 cf       	rjmp	.-96     	; 0xa60 <OS_Start+0x76>
		Cp->sp = CurrentSp;
		
		//Check if any timer ticks came in
		Kernel_Tick_Handler();

		switch(Cp->request)
     ac0:	10 e0       	ldi	r17, 0x00	; 0
     ac2:	c1 2f       	mov	r28, r17
     ac4:	20 e0       	ldi	r18, 0x00	; 0
     ac6:	d2 2f       	mov	r29, r18
{
	MUTEX_TYPE* m;
	// go through all mutex check if it owns a mutex
	int index;
	for (index=0; index<MAXMUTEX; index++) {
		if (Mutex[index].owner == Cp->pid) {
     ac8:	cc 9e       	mul	r12, r28
     aca:	f0 01       	movw	r30, r0
     acc:	cd 9e       	mul	r12, r29
     ace:	f0 0d       	add	r31, r0
     ad0:	11 24       	eor	r1, r1
     ad2:	ee 5c       	subi	r30, 0xCE	; 206
     ad4:	fd 4f       	sbci	r31, 0xFD	; 253
     ad6:	22 81       	ldd	r18, Z+2	; 0x02
     ad8:	33 81       	ldd	r19, Z+3	; 0x03
     ada:	e0 91 23 16 	lds	r30, 0x1623
     ade:	f0 91 24 16 	lds	r31, 0x1624
     ae2:	80 81       	ld	r24, Z
     ae4:	91 81       	ldd	r25, Z+1	; 0x01
     ae6:	28 17       	cp	r18, r24
     ae8:	39 07       	cpc	r19, r25
     aea:	09 f0       	breq	.+2      	; 0xaee <OS_Start+0x104>
     aec:	ac c0       	rjmp	.+344    	; 0xc46 <OS_Start+0x25c>
			// it owns a mutex unlock the mutex
			if (Mutex[index].num_of_process > 0) {
     aee:	cc 9e       	mul	r12, r28
     af0:	f0 01       	movw	r30, r0
     af2:	cd 9e       	mul	r12, r29
     af4:	f0 0d       	add	r31, r0
     af6:	11 24       	eor	r1, r1
     af8:	e8 57       	subi	r30, 0x78	; 120
     afa:	fd 4f       	sbci	r31, 0xFD	; 253
     afc:	80 81       	ld	r24, Z
     afe:	91 81       	ldd	r25, Z+1	; 0x01
     b00:	89 2b       	or	r24, r25
     b02:	09 f4       	brne	.+2      	; 0xb06 <OS_Start+0x11c>
     b04:	95 c0       	rjmp	.+298    	; 0xc30 <OS_Start+0x246>
				printf("something is waiting\n");
     b06:	80 e0       	ldi	r24, 0x00	; 0
     b08:	92 e0       	ldi	r25, 0x02	; 2
     b0a:	8e d3       	rcall	.+1820   	; 0x1228 <puts>
				// if there are other process waiting on the mutex
				PID p_dequeue = 0;
				unsigned int temp_order = Mutex[index].total_num + 1;
     b0c:	cc 9e       	mul	r12, r28
     b0e:	f0 01       	movw	r30, r0
     b10:	cd 9e       	mul	r12, r29
     b12:	f0 0d       	add	r31, r0
     b14:	11 24       	eor	r1, r1
     b16:	e6 57       	subi	r30, 0x76	; 118
     b18:	fd 4f       	sbci	r31, 0xFD	; 253
     b1a:	60 81       	ld	r22, Z
     b1c:	71 81       	ldd	r23, Z+1	; 0x01
     b1e:	6f 5f       	subi	r22, 0xFF	; 255
     b20:	7f 4f       	sbci	r23, 0xFF	; 255
		if (Mutex[index].owner == Cp->pid) {
			// it owns a mutex unlock the mutex
			if (Mutex[index].num_of_process > 0) {
				printf("something is waiting\n");
				// if there are other process waiting on the mutex
				PID p_dequeue = 0;
     b22:	e4 2c       	mov	r14, r4
     b24:	f3 2c       	mov	r15, r3
				unsigned int temp_order = Mutex[index].total_num + 1;
				PRIORITY temp_pri = LOWEST_PRIORITY + 1;
     b26:	18 2d       	mov	r17, r8
				int i;
				for (i=0; i<MAXTHREAD; i++) {
     b28:	24 2d       	mov	r18, r4
     b2a:	33 2d       	mov	r19, r3
					if (Mutex[index].priority_stack[i] < temp_pri) {
     b2c:	cc 9e       	mul	r12, r28
     b2e:	a0 01       	movw	r20, r0
     b30:	cd 9e       	mul	r12, r29
     b32:	50 0d       	add	r21, r0
     b34:	11 24       	eor	r1, r1
     b36:	ca 01       	movw	r24, r20
     b38:	8e 5c       	subi	r24, 0xCE	; 206
     b3a:	9d 4f       	sbci	r25, 0xFD	; 253
     b3c:	fc 01       	movw	r30, r24
     b3e:	e2 0f       	add	r30, r18
     b40:	f3 1f       	adc	r31, r19
     b42:	e6 a1       	ldd	r30, Z+38	; 0x26
     b44:	e1 17       	cp	r30, r17
     b46:	c8 f4       	brcc	.+50     	; 0xb7a <OS_Start+0x190>
						// found a task with higher priority
						temp_pri = Mutex[index].priority_stack[i];
     b48:	fc 01       	movw	r30, r24
     b4a:	e2 0f       	add	r30, r18
     b4c:	f3 1f       	adc	r31, r19
     b4e:	16 a1       	ldd	r17, Z+38	; 0x26
						temp_order = Mutex[index].order[i];
     b50:	f9 01       	movw	r30, r18
     b52:	7b 96       	adiw	r30, 0x1b	; 27
     b54:	ee 0f       	add	r30, r30
     b56:	ff 1f       	adc	r31, r31
     b58:	e4 0f       	add	r30, r20
     b5a:	f5 1f       	adc	r31, r21
     b5c:	ee 5c       	subi	r30, 0xCE	; 206
     b5e:	fd 4f       	sbci	r31, 0xFD	; 253
     b60:	60 81       	ld	r22, Z
     b62:	71 81       	ldd	r23, Z+1	; 0x01
						p_dequeue = Mutex[index].blocked_stack[i];
     b64:	f9 01       	movw	r30, r18
     b66:	33 96       	adiw	r30, 0x03	; 3
     b68:	ee 0f       	add	r30, r30
     b6a:	ff 1f       	adc	r31, r31
     b6c:	e4 0f       	add	r30, r20
     b6e:	f5 1f       	adc	r31, r21
     b70:	ee 5c       	subi	r30, 0xCE	; 206
     b72:	fd 4f       	sbci	r31, 0xFD	; 253
     b74:	e0 80       	ld	r14, Z
     b76:	f1 80       	ldd	r15, Z+1	; 0x01
     b78:	28 c0       	rjmp	.+80     	; 0xbca <OS_Start+0x1e0>
						} else if (Mutex[index].priority_stack[i] == temp_pri && temp_order < Mutex[index].order[i]) {
     b7a:	fc 01       	movw	r30, r24
     b7c:	e2 0f       	add	r30, r18
     b7e:	f3 1f       	adc	r31, r19
     b80:	e6 a1       	ldd	r30, Z+38	; 0x26
     b82:	1e 13       	cpse	r17, r30
     b84:	22 c0       	rjmp	.+68     	; 0xbca <OS_Start+0x1e0>
     b86:	f9 01       	movw	r30, r18
     b88:	7b 96       	adiw	r30, 0x1b	; 27
     b8a:	ee 0f       	add	r30, r30
     b8c:	ff 1f       	adc	r31, r31
     b8e:	e4 0f       	add	r30, r20
     b90:	f5 1f       	adc	r31, r21
     b92:	ee 5c       	subi	r30, 0xCE	; 206
     b94:	fd 4f       	sbci	r31, 0xFD	; 253
     b96:	01 90       	ld	r0, Z+
     b98:	f0 81       	ld	r31, Z
     b9a:	e0 2d       	mov	r30, r0
     b9c:	6e 17       	cp	r22, r30
     b9e:	7f 07       	cpc	r23, r31
     ba0:	a0 f4       	brcc	.+40     	; 0xbca <OS_Start+0x1e0>
						// same priority and came into the queue earlier
						temp_order = Mutex[index].order[i];
     ba2:	f9 01       	movw	r30, r18
     ba4:	7b 96       	adiw	r30, 0x1b	; 27
     ba6:	ee 0f       	add	r30, r30
     ba8:	ff 1f       	adc	r31, r31
     baa:	e4 0f       	add	r30, r20
     bac:	f5 1f       	adc	r31, r21
     bae:	ee 5c       	subi	r30, 0xCE	; 206
     bb0:	fd 4f       	sbci	r31, 0xFD	; 253
     bb2:	60 81       	ld	r22, Z
     bb4:	71 81       	ldd	r23, Z+1	; 0x01
						p_dequeue = Mutex[index].blocked_stack[i];
     bb6:	f9 01       	movw	r30, r18
     bb8:	33 96       	adiw	r30, 0x03	; 3
     bba:	ee 0f       	add	r30, r30
     bbc:	ff 1f       	adc	r31, r31
     bbe:	e4 0f       	add	r30, r20
     bc0:	f5 1f       	adc	r31, r21
     bc2:	ee 5c       	subi	r30, 0xCE	; 206
     bc4:	fd 4f       	sbci	r31, 0xFD	; 253
     bc6:	e0 80       	ld	r14, Z
     bc8:	f1 80       	ldd	r15, Z+1	; 0x01
				// if there are other process waiting on the mutex
				PID p_dequeue = 0;
				unsigned int temp_order = Mutex[index].total_num + 1;
				PRIORITY temp_pri = LOWEST_PRIORITY + 1;
				int i;
				for (i=0; i<MAXTHREAD; i++) {
     bca:	2f 5f       	subi	r18, 0xFF	; 255
     bcc:	3f 4f       	sbci	r19, 0xFF	; 255
     bce:	20 31       	cpi	r18, 0x10	; 16
     bd0:	31 05       	cpc	r19, r1
     bd2:	09 f0       	breq	.+2      	; 0xbd6 <OS_Start+0x1ec>
     bd4:	b3 cf       	rjmp	.-154    	; 0xb3c <OS_Start+0x152>
						temp_order = Mutex[index].order[i];
						p_dequeue = Mutex[index].blocked_stack[i];
					}
				}
				//dequeue index i
				Mutex[index].blocked_stack[i] = -1;
     bd6:	cc 9e       	mul	r12, r28
     bd8:	c0 01       	movw	r24, r0
     bda:	cd 9e       	mul	r12, r29
     bdc:	90 0d       	add	r25, r0
     bde:	11 24       	eor	r1, r1
     be0:	dc 01       	movw	r26, r24
     be2:	ae 5c       	subi	r26, 0xCE	; 206
     be4:	bd 4f       	sbci	r27, 0xFD	; 253
     be6:	5d 01       	movw	r10, r26
     be8:	ef ef       	ldi	r30, 0xFF	; 255
     bea:	ff ef       	ldi	r31, 0xFF	; 255
     bec:	97 96       	adiw	r26, 0x27	; 39
     bee:	fc 93       	st	X, r31
     bf0:	ee 93       	st	-X, r30
     bf2:	96 97       	sbiw	r26, 0x26	; 38
				Mutex[index].priority_stack[i] = LOWEST_PRIORITY+1;
     bf4:	d6 96       	adiw	r26, 0x36	; 54
     bf6:	8c 92       	st	X, r8
     bf8:	d6 97       	sbiw	r26, 0x36	; 54
				Mutex[index].order[i] = 0;
     bfa:	fd 01       	movw	r30, r26
     bfc:	ea 5a       	subi	r30, 0xAA	; 170
     bfe:	ff 4f       	sbci	r31, 0xFF	; 255
     c00:	11 82       	std	Z+1, r1	; 0x01
     c02:	10 82       	st	Z, r1
				--(Mutex[index].num_of_process);
     c04:	80 81       	ld	r24, Z
     c06:	91 81       	ldd	r25, Z+1	; 0x01
     c08:	01 97       	sbiw	r24, 0x01	; 1
     c0a:	91 83       	std	Z+1, r25	; 0x01
     c0c:	80 83       	st	Z, r24
				PD* target_p = findProcessByPID(p_dequeue);
     c0e:	c7 01       	movw	r24, r14
     c10:	42 db       	rcall	.-2428   	; 0x296 <findProcessByPID>
				Mutex[index].owner = p_dequeue;
     c12:	d5 01       	movw	r26, r10
     c14:	13 96       	adiw	r26, 0x03	; 3
     c16:	fc 92       	st	X, r15
     c18:	ee 92       	st	-X, r14
     c1a:	12 97       	sbiw	r26, 0x02	; 2
				Mutex[index].own_pri = temp_pri;			//keep track of new owner's priority;
     c1c:	f5 01       	movw	r30, r10
     c1e:	e6 5a       	subi	r30, 0xA6	; 166
     c20:	ff 4f       	sbci	r31, 0xFF	; 255
     c22:	10 83       	st	Z, r17
				target_p->state = READY;
     c24:	fc 01       	movw	r30, r24
     c26:	93 82       	std	Z+3, r9	; 0x03
				printf("target p is readd\n");
     c28:	85 e1       	ldi	r24, 0x15	; 21
     c2a:	92 e0       	ldi	r25, 0x02	; 2
     c2c:	fd d2       	rcall	.+1530   	; 0x1228 <puts>
     c2e:	0b c0       	rjmp	.+22     	; 0xc46 <OS_Start+0x25c>
			} else {
				Mutex[index].owner = 0;
     c30:	cc 9e       	mul	r12, r28
     c32:	f0 01       	movw	r30, r0
     c34:	cd 9e       	mul	r12, r29
     c36:	f0 0d       	add	r31, r0
     c38:	11 24       	eor	r1, r1
     c3a:	ee 5c       	subi	r30, 0xCE	; 206
     c3c:	fd 4f       	sbci	r31, 0xFD	; 253
     c3e:	13 82       	std	Z+3, r1	; 0x03
     c40:	12 82       	std	Z+2, r1	; 0x02
				Mutex[index].count = 0;
     c42:	15 82       	std	Z+5, r1	; 0x05
     c44:	14 82       	std	Z+4, r1	; 0x04
static void Kernel_Terminate_Task(void)
{
	MUTEX_TYPE* m;
	// go through all mutex check if it owns a mutex
	int index;
	for (index=0; index<MAXMUTEX; index++) {
     c46:	21 96       	adiw	r28, 0x01	; 1
     c48:	c8 30       	cpi	r28, 0x08	; 8
     c4a:	d1 05       	cpc	r29, r1
     c4c:	09 f0       	breq	.+2      	; 0xc50 <OS_Start+0x266>
     c4e:	3c cf       	rjmp	.-392    	; 0xac8 <OS_Start+0xde>
				Mutex[index].owner = 0;
				Mutex[index].count = 0;
			}
		}
	}
	Cp->state = DEAD;			//Mark the task as DEAD so its resources will be recycled later when new tasks are created
     c50:	e0 91 23 16 	lds	r30, 0x1623
     c54:	f0 91 24 16 	lds	r31, 0x1624
     c58:	13 82       	std	Z+3, r1	; 0x03
	--Task_Count;
     c5a:	80 91 2e 02 	lds	r24, 0x022E
     c5e:	90 91 2f 02 	lds	r25, 0x022F
     c62:	01 97       	sbiw	r24, 0x01	; 1
     c64:	90 93 2f 02 	sts	0x022F, r25
     c68:	80 93 2e 02 	sts	0x022E, r24
			Kernel_Create_Task(Cp->code, Cp->pri, Cp->arg);
			break;
			
			case TERMINATE:
			Kernel_Terminate_Task();
			Dispatch();					//Dispatch is only needed if the syscall requires running a different task  after it's done
     c6c:	46 dc       	rcall	.-1908   	; 0x4fa <Dispatch>
     c6e:	f8 ce       	rjmp	.-528    	; 0xa60 <OS_Start+0x76>

/*TODO: Check for mutex ownership. If PID owns any mutex, ignore this request*/
static void Kernel_Suspend_Task() 
{
	//Finds the process descriptor for the specified PID
	PD* p = findProcessByPID(Cp->request_arg);
     c70:	8e 81       	ldd	r24, Y+6	; 0x06
     c72:	9f 81       	ldd	r25, Y+7	; 0x07
     c74:	10 db       	rcall	.-2528   	; 0x296 <findProcessByPID>
	
	//Ensure the PID specified in the PD currently exists in the global process list
	if(p == NULL)
     c76:	00 97       	sbiw	r24, 0x00	; 0
     c78:	21 f4       	brne	.+8      	; 0xc82 <OS_Start+0x298>
	{
		#ifdef DEBUG
			printf("Kernel_Suspend_Task: PID not found in global process list!\n");
		#endif
		err = PID_NOT_FOUND_ERR;
     c7a:	85 e0       	ldi	r24, 0x05	; 5
     c7c:	80 93 20 16 	sts	0x1620, r24
     c80:	31 c0       	rjmp	.+98     	; 0xce4 <OS_Start+0x2fa>
		return;
	}
	
	//Ensure the task is not in a unsuspendable state
	if(p->state == DEAD || p->state == SUSPENDED)
     c82:	fc 01       	movw	r30, r24
     c84:	a3 81       	ldd	r26, Z+3	; 0x03
     c86:	aa 23       	and	r26, r26
     c88:	71 f0       	breq	.+28     	; 0xca6 <OS_Start+0x2bc>
     c8a:	a3 30       	cpi	r26, 0x03	; 3
     c8c:	61 f0       	breq	.+24     	; 0xca6 <OS_Start+0x2bc>
		return;
	}
	
	//Ensure the task is not currently owning a mutex
	for(int i=0; i<MAXMUTEX; i++) {
		if (Mutex[i].owner == p->pid) {
     c8e:	20 91 34 02 	lds	r18, 0x0234
     c92:	30 91 35 02 	lds	r19, 0x0235
     c96:	60 81       	ld	r22, Z
     c98:	71 81       	ldd	r23, Z+1	; 0x01
     c9a:	26 17       	cp	r18, r22
     c9c:	37 07       	cpc	r19, r23
     c9e:	99 f0       	breq	.+38     	; 0xcc6 <OS_Start+0x2dc>
     ca0:	27 2d       	mov	r18, r7
     ca2:	36 2d       	mov	r19, r6
     ca4:	04 c0       	rjmp	.+8      	; 0xcae <OS_Start+0x2c4>
	if(p->state == DEAD || p->state == SUSPENDED)
	{
		#ifdef DEBUG
		printf("Kernel_Suspend_Task: Trying to suspend a task that's in an unsuspendable state %d!\n", p->state);
		#endif
		err = SUSPEND_NONRUNNING_TASK_ERR;
     ca6:	86 e0       	ldi	r24, 0x06	; 6
     ca8:	80 93 20 16 	sts	0x1620, r24
     cac:	1b c0       	rjmp	.+54     	; 0xce4 <OS_Start+0x2fa>
		return;
	}
	
	//Ensure the task is not currently owning a mutex
	for(int i=0; i<MAXMUTEX; i++) {
		if (Mutex[i].owner == p->pid) {
     cae:	c2 9e       	mul	r12, r18
     cb0:	f0 01       	movw	r30, r0
     cb2:	c3 9e       	mul	r12, r19
     cb4:	f0 0d       	add	r31, r0
     cb6:	11 24       	eor	r1, r1
     cb8:	ee 5c       	subi	r30, 0xCE	; 206
     cba:	fd 4f       	sbci	r31, 0xFD	; 253
     cbc:	42 81       	ldd	r20, Z+2	; 0x02
     cbe:	53 81       	ldd	r21, Z+3	; 0x03
     cc0:	46 17       	cp	r20, r22
     cc2:	57 07       	cpc	r21, r23
     cc4:	21 f4       	brne	.+8      	; 0xcce <OS_Start+0x2e4>
			#ifdef DEBUG
			printf("Kernel_Suspend_Task: Trying to suspend a task that currently owns a mutex\n");
			#endif
			err = SUSPEND_NONRUNNING_TASK_ERR;
     cc6:	86 e0       	ldi	r24, 0x06	; 6
     cc8:	80 93 20 16 	sts	0x1620, r24
     ccc:	0b c0       	rjmp	.+22     	; 0xce4 <OS_Start+0x2fa>
		err = SUSPEND_NONRUNNING_TASK_ERR;
		return;
	}
	
	//Ensure the task is not currently owning a mutex
	for(int i=0; i<MAXMUTEX; i++) {
     cce:	2f 5f       	subi	r18, 0xFF	; 255
     cd0:	3f 4f       	sbci	r19, 0xFF	; 255
     cd2:	28 30       	cpi	r18, 0x08	; 8
     cd4:	31 05       	cpc	r19, r1
     cd6:	59 f7       	brne	.-42     	; 0xcae <OS_Start+0x2c4>
			return;
		}
	}
	
	//Save its current state and set it to SUSPENDED
	p->last_state = p->state;
     cd8:	fc 01       	movw	r30, r24
     cda:	a4 83       	std	Z+4, r26	; 0x04
	p->state = SUSPENDED;
     cdc:	23 e0       	ldi	r18, 0x03	; 3
     cde:	23 83       	std	Z+3, r18	; 0x03
	err = NO_ERR;
     ce0:	10 92 20 16 	sts	0x1620, r1
			Dispatch();					//Dispatch is only needed if the syscall requires running a different task  after it's done
			break;
		   
			case SUSPEND:
			Kernel_Suspend_Task();
			if(Cp->state != RUNNING) Dispatch();
     ce4:	e0 91 23 16 	lds	r30, 0x1623
     ce8:	f0 91 24 16 	lds	r31, 0x1624
     cec:	83 81       	ldd	r24, Z+3	; 0x03
     cee:	82 30       	cpi	r24, 0x02	; 2
     cf0:	09 f4       	brne	.+2      	; 0xcf4 <OS_Start+0x30a>
     cf2:	b6 ce       	rjmp	.-660    	; 0xa60 <OS_Start+0x76>
     cf4:	02 dc       	rcall	.-2044   	; 0x4fa <Dispatch>
     cf6:	b4 ce       	rjmp	.-664    	; 0xa60 <OS_Start+0x76>
}

static void Kernel_Resume_Task()
{
	//Finds the process descriptor for the specified PID
	PD* p = findProcessByPID(Cp->request_arg);
     cf8:	8e 81       	ldd	r24, Y+6	; 0x06
     cfa:	9f 81       	ldd	r25, Y+7	; 0x07
     cfc:	cc da       	rcall	.-2664   	; 0x296 <findProcessByPID>
	
	//Ensure the PID specified in the PD currently exists in the global process list
	if(p == NULL)
     cfe:	00 97       	sbiw	r24, 0x00	; 0
     d00:	21 f4       	brne	.+8      	; 0xd0a <OS_Start+0x320>
	{
		#ifdef DEBUG
			printf("Kernel_Resume_Task: PID not found in global process list!\n");
		#endif
		err = PID_NOT_FOUND_ERR;
     d02:	85 e0       	ldi	r24, 0x05	; 5
     d04:	80 93 20 16 	sts	0x1620, r24
     d08:	10 c0       	rjmp	.+32     	; 0xd2a <OS_Start+0x340>
		return;
	}
	
	//Ensure the task is currently in the SUSPENDED state
	if(p->state != SUSPENDED)
     d0a:	dc 01       	movw	r26, r24
     d0c:	13 96       	adiw	r26, 0x03	; 3
     d0e:	2c 91       	ld	r18, X
     d10:	23 30       	cpi	r18, 0x03	; 3
     d12:	21 f0       	breq	.+8      	; 0xd1c <OS_Start+0x332>
	{
		#ifdef DEBUG
		printf("Kernel_Resume_Task: Trying to resume a task that's not SUSPENDED!\n");
		printf("CURRENT STATE: %d\n", p->state);
		#endif
		err = RESUME_NONSUSPENDED_TASK_ERR;
     d14:	87 e0       	ldi	r24, 0x07	; 7
     d16:	80 93 20 16 	sts	0x1620, r24
     d1a:	07 c0       	rjmp	.+14     	; 0xd2a <OS_Start+0x340>
		return;
	}
	
	//Restore the previous state of the task
	p->state = p->last_state;
     d1c:	fc 01       	movw	r30, r24
     d1e:	24 81       	ldd	r18, Z+4	; 0x04
     d20:	23 83       	std	Z+3, r18	; 0x03
	p->last_state = SUSPENDED;			
     d22:	23 e0       	ldi	r18, 0x03	; 3
     d24:	24 83       	std	Z+4, r18	; 0x04
	err = NO_ERR;
     d26:	10 92 20 16 	sts	0x1620, r1
			if(Cp->state != RUNNING) Dispatch();
			break;
			
			case RESUME:
			Kernel_Resume_Task();
			Dispatch();
     d2a:	e7 db       	rcall	.-2098   	; 0x4fa <Dispatch>
     d2c:	99 ce       	rjmp	.-718    	; 0xa60 <OS_Start+0x76>
			break;
			
			case SLEEP:
			Cp->state = SLEEPING;
     d2e:	84 e0       	ldi	r24, 0x04	; 4
     d30:	8b 83       	std	Y+3, r24	; 0x03
			Dispatch();					
     d32:	e3 db       	rcall	.-2106   	; 0x4fa <Dispatch>
     d34:	95 ce       	rjmp	.-726    	; 0xa60 <OS_Start+0x76>
			break;
			
			case CREATE_E:
			Kernel_Create_Event();
     d36:	fa dc       	rcall	.-1548   	; 0x72c <Kernel_Create_Event>
     d38:	93 ce       	rjmp	.-730    	; 0xa60 <OS_Start+0x76>
	#endif
}

static void Kernel_Wait_Event(void)
{
	EVENT_TYPE* e = findEventByEventID(Cp->request_arg);
     d3a:	8e 81       	ldd	r24, Y+6	; 0x06
     d3c:	9f 81       	ldd	r25, Y+7	; 0x07
     d3e:	e1 da       	rcall	.-2622   	; 0x302 <findEventByEventID>
     d40:	fc 01       	movw	r30, r24
	
	if(e == NULL)
     d42:	89 2b       	or	r24, r25
     d44:	99 f1       	breq	.+102    	; 0xdac <OS_Start+0x3c2>
		#endif
		return;
	}
	
	//Ensure no one else is waiting for this same event
	if(e->owner > 0 && e->owner != Cp->pid)
     d46:	82 81       	ldd	r24, Z+2	; 0x02
     d48:	93 81       	ldd	r25, Z+3	; 0x03
     d4a:	00 97       	sbiw	r24, 0x00	; 0
     d4c:	69 f0       	breq	.+26     	; 0xd68 <OS_Start+0x37e>
     d4e:	a0 91 23 16 	lds	r26, 0x1623
     d52:	b0 91 24 16 	lds	r27, 0x1624
     d56:	2d 91       	ld	r18, X+
     d58:	3c 91       	ld	r19, X
     d5a:	82 17       	cp	r24, r18
     d5c:	93 07       	cpc	r25, r19
     d5e:	21 f0       	breq	.+8      	; 0xd68 <OS_Start+0x37e>
	{
		#ifdef DEBUG
			printf("Kernel_Wait_Event: The requested event is already being waited by PID %d\n", e->owner);
		#endif
		err = EVENT_NOT_FOUND_ERR;
     d60:	89 e0       	ldi	r24, 0x09	; 9
     d62:	80 93 20 16 	sts	0x1620, r24
     d66:	22 c0       	rjmp	.+68     	; 0xdac <OS_Start+0x3c2>
		return;
	}
	
	//Has this event been signaled already? If yes, "consume" event and keep executing the same task
	if(e->count > 0)
     d68:	84 81       	ldd	r24, Z+4	; 0x04
     d6a:	95 81       	ldd	r25, Z+5	; 0x05
     d6c:	89 2b       	or	r24, r25
     d6e:	81 f0       	breq	.+32     	; 0xd90 <OS_Start+0x3a6>
	{
		e->owner = 0;
     d70:	13 82       	std	Z+3, r1	; 0x03
     d72:	12 82       	std	Z+2, r1	; 0x02
		e->count = 0;
     d74:	15 82       	std	Z+5, r1	; 0x05
     d76:	14 82       	std	Z+4, r1	; 0x04
		e->id = 0;
     d78:	11 82       	std	Z+1, r1	; 0x01
     d7a:	10 82       	st	Z, r1
		--Event_Count;	
     d7c:	80 91 2c 02 	lds	r24, 0x022C
     d80:	90 91 2d 02 	lds	r25, 0x022D
     d84:	01 97       	sbiw	r24, 0x01	; 1
     d86:	90 93 2d 02 	sts	0x022D, r25
     d8a:	80 93 2c 02 	sts	0x022C, r24
     d8e:	0e c0       	rjmp	.+28     	; 0xdac <OS_Start+0x3c2>
		return;
	}
	
	//Set the owner of the requested event to the current task and put it into the WAIT EVENT state
	e->owner = Cp->pid;
     d90:	a0 91 23 16 	lds	r26, 0x1623
     d94:	b0 91 24 16 	lds	r27, 0x1624
     d98:	8d 91       	ld	r24, X+
     d9a:	9c 91       	ld	r25, X
     d9c:	11 97       	sbiw	r26, 0x01	; 1
     d9e:	93 83       	std	Z+3, r25	; 0x03
     da0:	82 83       	std	Z+2, r24	; 0x02
	Cp->state = WAIT_EVENT;
     da2:	85 e0       	ldi	r24, 0x05	; 5
     da4:	13 96       	adiw	r26, 0x03	; 3
     da6:	8c 93       	st	X, r24
	err = NO_ERR;
     da8:	10 92 20 16 	sts	0x1620, r1
			Kernel_Create_Event();
			break;
			
			case WAIT_E:
			Kernel_Wait_Event();	
			if(Cp->state != RUNNING) Dispatch();	//Don't dispatch to a different task if the event is already siganlled
     dac:	e0 91 23 16 	lds	r30, 0x1623
     db0:	f0 91 24 16 	lds	r31, 0x1624
     db4:	83 81       	ldd	r24, Z+3	; 0x03
     db6:	82 30       	cpi	r24, 0x02	; 2
     db8:	09 f4       	brne	.+2      	; 0xdbc <OS_Start+0x3d2>
     dba:	52 ce       	rjmp	.-860    	; 0xa60 <OS_Start+0x76>
     dbc:	9e db       	rcall	.-2244   	; 0x4fa <Dispatch>
     dbe:	50 ce       	rjmp	.-864    	; 0xa60 <OS_Start+0x76>
	err = NO_ERR;
}

static void Kernel_Signal_Event(void)
{
	EVENT_TYPE* e = findEventByEventID(Cp->request_arg);
     dc0:	8e 81       	ldd	r24, Y+6	; 0x06
     dc2:	9f 81       	ldd	r25, Y+7	; 0x07
     dc4:	9e da       	rcall	.-2756   	; 0x302 <findEventByEventID>
     dc6:	ec 01       	movw	r28, r24
	PD *e_owner;
	
	if(e == NULL)
     dc8:	89 2b       	or	r24, r25
     dca:	61 f1       	breq	.+88     	; 0xe24 <OS_Start+0x43a>
		#endif
		return;
	}
	
	//Increment the event counter if needed 
	if(MAX_EVENT_SIG_MISS == 0 || e->count < MAX_EVENT_SIG_MISS)
     dcc:	8c 81       	ldd	r24, Y+4	; 0x04
     dce:	9d 81       	ldd	r25, Y+5	; 0x05
     dd0:	89 2b       	or	r24, r25
     dd2:	11 f4       	brne	.+4      	; 0xdd8 <OS_Start+0x3ee>
		e->count++;
     dd4:	7c 82       	std	Y+4, r7	; 0x04
     dd6:	6d 82       	std	Y+5, r6	; 0x05
	
	//If the event is unowned, return
	if(e->owner == 0)
     dd8:	8a 81       	ldd	r24, Y+2	; 0x02
     dda:	9b 81       	ldd	r25, Y+3	; 0x03
     ddc:	00 97       	sbiw	r24, 0x00	; 0
     dde:	19 f4       	brne	.+6      	; 0xde6 <OS_Start+0x3fc>
	{
		#ifdef DEBUG
		printf("Kernel_Signal_Event: *WARNING* The requested event is not being waited by anyone!\n");
		#endif
		err = SIGNAL_UNOWNED_EVENT_ERR;
     de0:	80 92 20 16 	sts	0x1620, r8
     de4:	1f c0       	rjmp	.+62     	; 0xe24 <OS_Start+0x43a>
		return;
	}
	
	//Fetch the owner's PD and ensure it's still valid
	e_owner = findProcessByPID(e->owner);
     de6:	57 da       	rcall	.-2898   	; 0x296 <findProcessByPID>
	if(e_owner == NULL)
     de8:	00 97       	sbiw	r24, 0x00	; 0
     dea:	21 f4       	brne	.+8      	; 0xdf4 <OS_Start+0x40a>
	{
		#ifdef DEBUG
		printf("Kernel_Signal_Event: Event owner's PID not found in global process list!\n");
		#endif
		err = PID_NOT_FOUND_ERR;
     dec:	85 e0       	ldi	r24, 0x05	; 5
     dee:	80 93 20 16 	sts	0x1620, r24
     df2:	18 c0       	rjmp	.+48     	; 0xe24 <OS_Start+0x43a>
		return;
	}
	
	//Wake up the owner of the event by setting its state to READY if it's active. The event is "consumed"
	if(e_owner->state == WAIT_EVENT)
     df4:	dc 01       	movw	r26, r24
     df6:	13 96       	adiw	r26, 0x03	; 3
     df8:	2c 91       	ld	r18, X
     dfa:	13 97       	sbiw	r26, 0x03	; 3
     dfc:	25 30       	cpi	r18, 0x05	; 5
     dfe:	91 f4       	brne	.+36     	; 0xe24 <OS_Start+0x43a>
	{
		e->owner = 0;
     e00:	1b 82       	std	Y+3, r1	; 0x03
     e02:	1a 82       	std	Y+2, r1	; 0x02
		e->count = 0;
     e04:	1d 82       	std	Y+5, r1	; 0x05
     e06:	1c 82       	std	Y+4, r1	; 0x04
		e->id = 0;
     e08:	19 82       	std	Y+1, r1	; 0x01
     e0a:	18 82       	st	Y, r1
		--Event_Count;
     e0c:	20 91 2c 02 	lds	r18, 0x022C
     e10:	30 91 2d 02 	lds	r19, 0x022D
     e14:	21 50       	subi	r18, 0x01	; 1
     e16:	31 09       	sbc	r19, r1
     e18:	30 93 2d 02 	sts	0x022D, r19
     e1c:	20 93 2c 02 	sts	0x022C, r18
		e_owner->state = READY;
     e20:	13 96       	adiw	r26, 0x03	; 3
     e22:	9c 92       	st	X, r9
			if(Cp->state != RUNNING) Dispatch();	//Don't dispatch to a different task if the event is already siganlled
			break;
			
			case SIGNAL_E:
			Kernel_Signal_Event();
			Dispatch();
     e24:	6a db       	rcall	.-2348   	; 0x4fa <Dispatch>
     e26:	1c ce       	rjmp	.-968    	; 0xa60 <OS_Start+0x76>
			break;
			
			case CREATE_M:
			Kernel_Create_Mutex();
     e28:	ce dc       	rcall	.-1636   	; 0x7c6 <Kernel_Create_Mutex>
     e2a:	1a ce       	rjmp	.-972    	; 0xa60 <OS_Start+0x76>

static void Dispatch();

static void Kernel_Lock_Mutex(void)
{
	MUTEX_TYPE* m = findMutexByMutexID(Cp->request_arg);
     e2c:	8e 81       	ldd	r24, Y+6	; 0x06
     e2e:	9f 81       	ldd	r25, Y+7	; 0x07
     e30:	a0 da       	rcall	.-2752   	; 0x372 <findMutexByMutexID>
     e32:	ec 01       	movw	r28, r24
	PD *m_owner = findProcessByPID(m->owner);
     e34:	8a 81       	ldd	r24, Y+2	; 0x02
     e36:	9b 81       	ldd	r25, Y+3	; 0x03
     e38:	2e da       	rcall	.-2980   	; 0x296 <findProcessByPID>
	
	if(m == NULL)
     e3a:	20 97       	sbiw	r28, 0x00	; 0
     e3c:	09 f4       	brne	.+2      	; 0xe40 <OS_Start+0x456>
     e3e:	10 ce       	rjmp	.-992    	; 0xa60 <OS_Start+0x76>
		#endif
		return;
	}
	
	// if mutex is free
	if(m->owner == 0)
     e40:	2a 81       	ldd	r18, Y+2	; 0x02
     e42:	3b 81       	ldd	r19, Y+3	; 0x03
     e44:	21 15       	cp	r18, r1
     e46:	31 05       	cpc	r19, r1
     e48:	79 f4       	brne	.+30     	; 0xe68 <OS_Start+0x47e>
	{
		m->owner = Cp->pid;
     e4a:	e0 91 23 16 	lds	r30, 0x1623
     e4e:	f0 91 24 16 	lds	r31, 0x1624
     e52:	80 81       	ld	r24, Z
     e54:	91 81       	ldd	r25, Z+1	; 0x01
     e56:	9b 83       	std	Y+3, r25	; 0x03
     e58:	8a 83       	std	Y+2, r24	; 0x02
		m->count = 1;
     e5a:	7c 82       	std	Y+4, r7	; 0x04
     e5c:	6d 82       	std	Y+5, r6	; 0x05
		m->own_pri = Cp->pri;				// keep track of the original priority of the owner
     e5e:	82 81       	ldd	r24, Z+2	; 0x02
     e60:	c6 5a       	subi	r28, 0xA6	; 166
     e62:	df 4f       	sbci	r29, 0xFF	; 255
     e64:	88 83       	st	Y, r24
     e66:	fc cd       	rjmp	.-1032   	; 0xa60 <OS_Start+0x76>
		return;
	} else if (m->owner == Cp->pid) {
     e68:	a0 91 23 16 	lds	r26, 0x1623
     e6c:	b0 91 24 16 	lds	r27, 0x1624
     e70:	4d 91       	ld	r20, X+
     e72:	5c 91       	ld	r21, X
     e74:	11 97       	sbiw	r26, 0x01	; 1
     e76:	24 17       	cp	r18, r20
     e78:	35 07       	cpc	r19, r21
     e7a:	31 f4       	brne	.+12     	; 0xe88 <OS_Start+0x49e>
		// if it has locked by the current process
		++(m->count);
     e7c:	8c 81       	ldd	r24, Y+4	; 0x04
     e7e:	9d 81       	ldd	r25, Y+5	; 0x05
     e80:	01 96       	adiw	r24, 0x01	; 1
     e82:	9d 83       	std	Y+5, r25	; 0x05
     e84:	8c 83       	std	Y+4, r24	; 0x04
     e86:	ec cd       	rjmp	.-1064   	; 0xa60 <OS_Start+0x76>
		return;
	} else {
		Cp->state = WAIT_MUTEX;								//put cp into state wait mutex
     e88:	26 e0       	ldi	r18, 0x06	; 6
     e8a:	13 96       	adiw	r26, 0x03	; 3
     e8c:	2c 93       	st	X, r18
     e8e:	13 97       	sbiw	r26, 0x03	; 3
		//enqueue cp to stack
		++(m->num_of_process);
     e90:	fe 01       	movw	r30, r28
     e92:	ea 5a       	subi	r30, 0xAA	; 170
     e94:	ff 4f       	sbci	r31, 0xFF	; 255
     e96:	20 81       	ld	r18, Z
     e98:	31 81       	ldd	r19, Z+1	; 0x01
     e9a:	2f 5f       	subi	r18, 0xFF	; 255
     e9c:	3f 4f       	sbci	r19, 0xFF	; 255
     e9e:	31 83       	std	Z+1, r19	; 0x01
     ea0:	20 83       	st	Z, r18
		++(m->total_num);
     ea2:	32 96       	adiw	r30, 0x02	; 2
     ea4:	60 81       	ld	r22, Z
     ea6:	71 81       	ldd	r23, Z+1	; 0x01
     ea8:	6f 5f       	subi	r22, 0xFF	; 255
     eaa:	7f 4f       	sbci	r23, 0xFF	; 255
     eac:	71 83       	std	Z+1, r23	; 0x01
     eae:	60 83       	st	Z, r22
		for (int i=0; i<MAXTHREAD; i++) {
			if (m->blocked_stack[i] == -1){
     eb0:	2e 81       	ldd	r18, Y+6	; 0x06
     eb2:	3f 81       	ldd	r19, Y+7	; 0x07
     eb4:	2f 3f       	cpi	r18, 0xFF	; 255
     eb6:	3f 4f       	sbci	r19, 0xFF	; 255
     eb8:	51 f0       	breq	.+20     	; 0xece <OS_Start+0x4e4>
     eba:	fe 01       	movw	r30, r28
     ebc:	38 96       	adiw	r30, 0x08	; 8
	} else {
		Cp->state = WAIT_MUTEX;								//put cp into state wait mutex
		//enqueue cp to stack
		++(m->num_of_process);
		++(m->total_num);
		for (int i=0; i<MAXTHREAD; i++) {
     ebe:	27 2d       	mov	r18, r7
     ec0:	36 2d       	mov	r19, r6
			if (m->blocked_stack[i] == -1){
     ec2:	41 91       	ld	r20, Z+
     ec4:	51 91       	ld	r21, Z+
     ec6:	4f 3f       	cpi	r20, 0xFF	; 255
     ec8:	5f 4f       	sbci	r21, 0xFF	; 255
     eca:	b9 f4       	brne	.+46     	; 0xefa <OS_Start+0x510>
     ecc:	02 c0       	rjmp	.+4      	; 0xed2 <OS_Start+0x4e8>
	} else {
		Cp->state = WAIT_MUTEX;								//put cp into state wait mutex
		//enqueue cp to stack
		++(m->num_of_process);
		++(m->total_num);
		for (int i=0; i<MAXTHREAD; i++) {
     ece:	20 e0       	ldi	r18, 0x00	; 0
     ed0:	30 e0       	ldi	r19, 0x00	; 0
			if (m->blocked_stack[i] == -1){
				m->blocked_stack[i] = Cp->pid;
     ed2:	4d 91       	ld	r20, X+
     ed4:	5c 91       	ld	r21, X
     ed6:	11 97       	sbiw	r26, 0x01	; 1
     ed8:	f9 01       	movw	r30, r18
     eda:	ee 0f       	add	r30, r30
     edc:	ff 1f       	adc	r31, r31
     ede:	ec 0f       	add	r30, r28
     ee0:	fd 1f       	adc	r31, r29
     ee2:	57 83       	std	Z+7, r21	; 0x07
     ee4:	46 83       	std	Z+6, r20	; 0x06
				m->order[i] = m->total_num;
     ee6:	77 ab       	std	Z+55, r23	; 0x37
     ee8:	66 ab       	std	Z+54, r22	; 0x36
				m->priority_stack[i] = Cp->pri;
     eea:	12 96       	adiw	r26, 0x02	; 2
     eec:	4c 91       	ld	r20, X
     eee:	12 97       	sbiw	r26, 0x02	; 2
     ef0:	fe 01       	movw	r30, r28
     ef2:	e2 0f       	add	r30, r18
     ef4:	f3 1f       	adc	r31, r19
     ef6:	46 a3       	std	Z+38, r20	; 0x26
     ef8:	05 c0       	rjmp	.+10     	; 0xf04 <OS_Start+0x51a>
	} else {
		Cp->state = WAIT_MUTEX;								//put cp into state wait mutex
		//enqueue cp to stack
		++(m->num_of_process);
		++(m->total_num);
		for (int i=0; i<MAXTHREAD; i++) {
     efa:	2f 5f       	subi	r18, 0xFF	; 255
     efc:	3f 4f       	sbci	r19, 0xFF	; 255
     efe:	20 31       	cpi	r18, 0x10	; 16
     f00:	31 05       	cpc	r19, r1
     f02:	f9 f6       	brne	.-66     	; 0xec2 <OS_Start+0x4d8>
			}
		}
		// end of enqueue
		
		//if cp's priority is higher than the owner
		if (Cp->pri < m_owner->pri) {
     f04:	12 96       	adiw	r26, 0x02	; 2
     f06:	3c 91       	ld	r19, X
     f08:	12 97       	sbiw	r26, 0x02	; 2
     f0a:	fc 01       	movw	r30, r24
     f0c:	22 81       	ldd	r18, Z+2	; 0x02
     f0e:	32 17       	cp	r19, r18
     f10:	18 f4       	brcc	.+6      	; 0xf18 <OS_Start+0x52e>
			m_owner->pri = Cp->pri;				// the owner gets cp's priority
     f12:	12 96       	adiw	r26, 0x02	; 2
     f14:	2c 91       	ld	r18, X
     f16:	22 83       	std	Z+2, r18	; 0x02
		}
		Dispatch();
     f18:	f0 da       	rcall	.-2592   	; 0x4fa <Dispatch>
     f1a:	a2 cd       	rjmp	.-1212   	; 0xa60 <OS_Start+0x76>
	}
}

static void Kernel_Unlock_Mutex(void)
{
	MUTEX_TYPE* m = findMutexByMutexID(Cp->request_arg);
     f1c:	8e 81       	ldd	r24, Y+6	; 0x06
     f1e:	9f 81       	ldd	r25, Y+7	; 0x07
     f20:	28 da       	rcall	.-2992   	; 0x372 <findMutexByMutexID>
     f22:	ec 01       	movw	r28, r24
	PD *m_owner = findProcessByPID(m->owner);
     f24:	8a 81       	ldd	r24, Y+2	; 0x02
     f26:	9b 81       	ldd	r25, Y+3	; 0x03
     f28:	b6 d9       	rcall	.-3220   	; 0x296 <findProcessByPID>
     f2a:	8c 01       	movw	r16, r24
	
	if(m == NULL)
     f2c:	20 97       	sbiw	r28, 0x00	; 0
     f2e:	09 f4       	brne	.+2      	; 0xf32 <OS_Start+0x548>
     f30:	97 cd       	rjmp	.-1234   	; 0xa60 <OS_Start+0x76>
		printf("Kernel_Unlock_Mutex: Error finding requested mutex!\n");
		#endif
		return;
	}
	
	if(m->owner != Cp->pid){
     f32:	e0 91 23 16 	lds	r30, 0x1623
     f36:	f0 91 24 16 	lds	r31, 0x1624
     f3a:	80 81       	ld	r24, Z
     f3c:	91 81       	ldd	r25, Z+1	; 0x01
     f3e:	2a 81       	ldd	r18, Y+2	; 0x02
     f40:	3b 81       	ldd	r19, Y+3	; 0x03
     f42:	28 17       	cp	r18, r24
     f44:	39 07       	cpc	r19, r25
     f46:	09 f0       	breq	.+2      	; 0xf4a <OS_Start+0x560>
     f48:	8b cd       	rjmp	.-1258   	; 0xa60 <OS_Start+0x76>
		#ifdef DEBUG
		printf("Kernel_Unlock_Mutex: The owner is not the current process\n");
		#endif
		return;
	} else if (m->count > 1) {
     f4a:	8c 81       	ldd	r24, Y+4	; 0x04
     f4c:	9d 81       	ldd	r25, Y+5	; 0x05
     f4e:	82 30       	cpi	r24, 0x02	; 2
     f50:	91 05       	cpc	r25, r1
     f52:	20 f0       	brcs	.+8      	; 0xf5c <OS_Start+0x572>
		// M is locked more than once
		--(m->count);
     f54:	01 97       	sbiw	r24, 0x01	; 1
     f56:	9d 83       	std	Y+5, r25	; 0x05
     f58:	8c 83       	std	Y+4, r24	; 0x04
     f5a:	82 cd       	rjmp	.-1276   	; 0xa60 <OS_Start+0x76>
	} else if (m->num_of_process > 0) {
     f5c:	fe 01       	movw	r30, r28
     f5e:	ea 5a       	subi	r30, 0xAA	; 170
     f60:	ff 4f       	sbci	r31, 0xFF	; 255
     f62:	a0 80       	ld	r10, Z
     f64:	b1 80       	ldd	r11, Z+1	; 0x01
     f66:	a1 14       	cp	r10, r1
     f68:	b1 04       	cpc	r11, r1
     f6a:	09 f4       	brne	.+2      	; 0xf6e <OS_Start+0x584>
     f6c:	55 c0       	rjmp	.+170    	; 0x1018 <OS_Start+0x62e>
		// there are tasks waiting on the mutex
		// deque the task with highest priority
		PID p_dequeue = 0;
		unsigned int temp_order = m->total_num + 1;
     f6e:	32 96       	adiw	r30, 0x02	; 2
     f70:	60 81       	ld	r22, Z
     f72:	71 81       	ldd	r23, Z+1	; 0x01
     f74:	6f 5f       	subi	r22, 0xFF	; 255
     f76:	7f 4f       	sbci	r23, 0xFF	; 255
     f78:	ce 01       	movw	r24, r28
     f7a:	86 96       	adiw	r24, 0x26	; 38
     f7c:	b2 97       	sbiw	r30, 0x22	; 34
     f7e:	de 01       	movw	r26, r28
     f80:	16 96       	adiw	r26, 0x06	; 6
     f82:	ae 01       	movw	r20, r28
     f84:	4a 5a       	subi	r20, 0xAA	; 170
     f86:	5f 4f       	sbci	r21, 0xFF	; 255
		// M is locked more than once
		--(m->count);
	} else if (m->num_of_process > 0) {
		// there are tasks waiting on the mutex
		// deque the task with highest priority
		PID p_dequeue = 0;
     f88:	e1 2c       	mov	r14, r1
     f8a:	d1 2c       	mov	r13, r1
		unsigned int temp_order = m->total_num + 1;
		PRIORITY temp_pri = LOWEST_PRIORITY + 1;
     f8c:	f8 2c       	mov	r15, r8
     f8e:	9e 01       	movw	r18, r28
     f90:	ec 01       	movw	r28, r24
		int i;
		for (i=0; i<MAXTHREAD; i++) {
			if (m->priority_stack[i] < temp_pri) {
     f92:	29 90       	ld	r2, Y+
     f94:	2f 14       	cp	r2, r15
     f96:	40 f4       	brcc	.+16     	; 0xfa8 <OS_Start+0x5be>
				// found a task with higher priority
				temp_pri = m->priority_stack[i];
				temp_order = m->order[i];
     f98:	60 81       	ld	r22, Z
     f9a:	71 81       	ldd	r23, Z+1	; 0x01
				p_dequeue = m->blocked_stack[i];
     f9c:	ec 90       	ld	r14, X
     f9e:	11 96       	adiw	r26, 0x01	; 1
     fa0:	dc 90       	ld	r13, X
     fa2:	11 97       	sbiw	r26, 0x01	; 1
		PRIORITY temp_pri = LOWEST_PRIORITY + 1;
		int i;
		for (i=0; i<MAXTHREAD; i++) {
			if (m->priority_stack[i] < temp_pri) {
				// found a task with higher priority
				temp_pri = m->priority_stack[i];
     fa4:	f2 2c       	mov	r15, r2
     fa6:	0f c0       	rjmp	.+30     	; 0xfc6 <OS_Start+0x5dc>
				temp_order = m->order[i];
				p_dequeue = m->blocked_stack[i];
			} else if (m->priority_stack[i] == temp_pri && temp_order < m->order[i]) {
     fa8:	2f 10       	cpse	r2, r15
     faa:	0d c0       	rjmp	.+26     	; 0xfc6 <OS_Start+0x5dc>
     fac:	80 81       	ld	r24, Z
     fae:	91 81       	ldd	r25, Z+1	; 0x01
     fb0:	68 17       	cp	r22, r24
     fb2:	79 07       	cpc	r23, r25
     fb4:	38 f4       	brcc	.+14     	; 0xfc4 <OS_Start+0x5da>
				// same priority and came into the queue earlier
				temp_order = m->order[i];
				p_dequeue = m->blocked_stack[i];
     fb6:	ec 90       	ld	r14, X
     fb8:	11 96       	adiw	r26, 0x01	; 1
     fba:	dc 90       	ld	r13, X
     fbc:	11 97       	sbiw	r26, 0x01	; 1
     fbe:	f2 2c       	mov	r15, r2
				temp_pri = m->priority_stack[i];
				temp_order = m->order[i];
				p_dequeue = m->blocked_stack[i];
			} else if (m->priority_stack[i] == temp_pri && temp_order < m->order[i]) {
				// same priority and came into the queue earlier
				temp_order = m->order[i];
     fc0:	bc 01       	movw	r22, r24
     fc2:	01 c0       	rjmp	.+2      	; 0xfc6 <OS_Start+0x5dc>
			if (m->priority_stack[i] < temp_pri) {
				// found a task with higher priority
				temp_pri = m->priority_stack[i];
				temp_order = m->order[i];
				p_dequeue = m->blocked_stack[i];
			} else if (m->priority_stack[i] == temp_pri && temp_order < m->order[i]) {
     fc4:	f2 2c       	mov	r15, r2
     fc6:	32 96       	adiw	r30, 0x02	; 2
     fc8:	12 96       	adiw	r26, 0x02	; 2
		// deque the task with highest priority
		PID p_dequeue = 0;
		unsigned int temp_order = m->total_num + 1;
		PRIORITY temp_pri = LOWEST_PRIORITY + 1;
		int i;
		for (i=0; i<MAXTHREAD; i++) {
     fca:	e4 17       	cp	r30, r20
     fcc:	f5 07       	cpc	r31, r21
     fce:	09 f7       	brne	.-62     	; 0xf92 <OS_Start+0x5a8>
     fd0:	e9 01       	movw	r28, r18
				temp_order = m->order[i];
				p_dequeue = m->blocked_stack[i];
			}
		}
		//dequeue index i
		m->blocked_stack[i] = -1;
     fd2:	2f ef       	ldi	r18, 0xFF	; 255
     fd4:	3f ef       	ldi	r19, 0xFF	; 255
     fd6:	3f a3       	std	Y+39, r19	; 0x27
     fd8:	2e a3       	std	Y+38, r18	; 0x26
		m->priority_stack[i] = LOWEST_PRIORITY+1;
     fda:	8e aa       	std	Y+54, r8	; 0x36
		m->order[i] = 0;
		--(m->num_of_process);
     fdc:	fe 01       	movw	r30, r28
     fde:	ea 5a       	subi	r30, 0xAA	; 170
     fe0:	ff 4f       	sbci	r31, 0xFF	; 255
     fe2:	31 e0       	ldi	r19, 0x01	; 1
     fe4:	a3 1a       	sub	r10, r19
     fe6:	b1 08       	sbc	r11, r1
     fe8:	b1 82       	std	Z+1, r11	; 0x01
     fea:	a0 82       	st	Z, r10
		PD* target_p = findProcessByPID(p_dequeue);
     fec:	8e 2d       	mov	r24, r14
     fee:	9d 2d       	mov	r25, r13
     ff0:	52 d9       	rcall	.-3420   	; 0x296 <findProcessByPID>
		m_owner->pri = m->own_pri;		//reset owner's priority
     ff2:	fe 01       	movw	r30, r28
     ff4:	e6 5a       	subi	r30, 0xA6	; 166
     ff6:	ff 4f       	sbci	r31, 0xFF	; 255
     ff8:	20 81       	ld	r18, Z
     ffa:	d8 01       	movw	r26, r16
     ffc:	12 96       	adiw	r26, 0x02	; 2
     ffe:	2c 93       	st	X, r18
		m->owner = p_dequeue;
    1000:	ea 82       	std	Y+2, r14	; 0x02
    1002:	db 82       	std	Y+3, r13	; 0x03
		m->own_pri = temp_pri;			//keep track of new owner's priority;
    1004:	f0 82       	st	Z, r15
		target_p->state = READY;
    1006:	fc 01       	movw	r30, r24
    1008:	93 82       	std	Z+3, r9	; 0x03
		Cp->state = READY;
    100a:	e0 91 23 16 	lds	r30, 0x1623
    100e:	f0 91 24 16 	lds	r31, 0x1624
    1012:	93 82       	std	Z+3, r9	; 0x03
		Dispatch();
    1014:	72 da       	rcall	.-2844   	; 0x4fa <Dispatch>
    1016:	24 cd       	rjmp	.-1464   	; 0xa60 <OS_Start+0x76>
		return;
	} else {
		m->owner = 0;
    1018:	1b 82       	std	Y+3, r1	; 0x03
    101a:	1a 82       	std	Y+2, r1	; 0x02
		m->count = 0;
    101c:	1d 82       	std	Y+5, r1	; 0x05
    101e:	1c 82       	std	Y+4, r1	; 0x04
		m_owner->pri = m->own_pri;		//reset owner's priority
    1020:	c6 5a       	subi	r28, 0xA6	; 166
    1022:	df 4f       	sbci	r29, 0xFF	; 255
    1024:	88 81       	ld	r24, Y
    1026:	d8 01       	movw	r26, r16
    1028:	12 96       	adiw	r26, 0x02	; 2
    102a:	8c 93       	st	X, r24
    102c:	19 cd       	rjmp	.-1486   	; 0xa60 <OS_Start+0x76>
			//Does this need dispatch under any circumstances?
			break;
		   
			case YIELD:
			case NONE:					// NONE could be caused by a timer interrupt
			Cp->state = READY;
    102e:	9b 82       	std	Y+3, r9	; 0x03
			Dispatch();
    1030:	64 da       	rcall	.-2872   	; 0x4fa <Dispatch>
    1032:	16 cd       	rjmp	.-1492   	; 0xa60 <OS_Start+0x76>
			break;
       
			//Invalid request code, just ignore
			default:
				err = INVALID_KERNET_REQUEST_ERR;
    1034:	50 92 20 16 	sts	0x1620, r5
    1038:	13 cd       	rjmp	.-1498   	; 0xa60 <OS_Start+0x76>
		#endif
		
		Next_Kernel_Request();
		/* NEVER RETURNS!!! */
	}
}
    103a:	df 91       	pop	r29
    103c:	cf 91       	pop	r28
    103e:	1f 91       	pop	r17
    1040:	0f 91       	pop	r16
    1042:	ff 90       	pop	r15
    1044:	ef 90       	pop	r14
    1046:	df 90       	pop	r13
    1048:	cf 90       	pop	r12
    104a:	bf 90       	pop	r11
    104c:	af 90       	pop	r10
    104e:	9f 90       	pop	r9
    1050:	8f 90       	pop	r8
    1052:	7f 90       	pop	r7
    1054:	6f 90       	pop	r6
    1056:	5f 90       	pop	r5
    1058:	4f 90       	pop	r4
    105a:	3f 90       	pop	r3
    105c:	2f 90       	pop	r2
    105e:	08 95       	ret

00001060 <Task_Create>:
	}
	Disable_Interrupt();
	
	Cp->request = SIGNAL_E;
	Cp->request_arg = e;
	Enter_Kernel();	
    1060:	20 91 1c 16 	lds	r18, 0x161C
    1064:	30 91 1d 16 	lds	r19, 0x161D
    1068:	23 2b       	or	r18, r19
    106a:	81 f0       	breq	.+32     	; 0x108c <Task_Create+0x2c>
    106c:	f8 94       	cli
    106e:	e0 91 23 16 	lds	r30, 0x1623
    1072:	f0 91 24 16 	lds	r31, 0x1624
    1076:	62 83       	std	Z+2, r22	; 0x02
    1078:	51 87       	std	Z+9, r21	; 0x09
    107a:	40 87       	std	Z+8, r20	; 0x08
    107c:	21 e0       	ldi	r18, 0x01	; 1
    107e:	25 83       	std	Z+5, r18	; 0x05
    1080:	e4 5f       	subi	r30, 0xF4	; 244
    1082:	fe 4f       	sbci	r31, 0xFE	; 254
    1084:	91 83       	std	Z+1, r25	; 0x01
    1086:	80 83       	st	Z, r24
    1088:	b1 d8       	rcall	.-3742   	; 0x1ec <Enter_Kernel>
    108a:	01 c0       	rjmp	.+2      	; 0x108e <Task_Create+0x2e>
    108c:	cc da       	rcall	.-2664   	; 0x626 <Kernel_Create_Task>
    108e:	80 91 20 16 	lds	r24, 0x1620
    1092:	84 30       	cpi	r24, 0x04	; 4
    1094:	29 f0       	breq	.+10     	; 0x10a0 <Task_Create+0x40>
    1096:	80 91 1a 16 	lds	r24, 0x161A
    109a:	90 91 1b 16 	lds	r25, 0x161B
    109e:	08 95       	ret
    10a0:	80 e0       	ldi	r24, 0x00	; 0
    10a2:	90 e0       	ldi	r25, 0x00	; 0
    10a4:	08 95       	ret

000010a6 <Task_Terminate>:
    10a6:	80 91 1c 16 	lds	r24, 0x161C
    10aa:	90 91 1d 16 	lds	r25, 0x161D
    10ae:	89 2b       	or	r24, r25
    10b0:	21 f4       	brne	.+8      	; 0x10ba <Task_Terminate+0x14>
    10b2:	83 e0       	ldi	r24, 0x03	; 3
    10b4:	80 93 20 16 	sts	0x1620, r24
    10b8:	08 95       	ret
    10ba:	f8 94       	cli
    10bc:	e0 91 23 16 	lds	r30, 0x1623
    10c0:	f0 91 24 16 	lds	r31, 0x1624
    10c4:	83 e0       	ldi	r24, 0x03	; 3
    10c6:	85 83       	std	Z+5, r24	; 0x05
    10c8:	91 c8       	rjmp	.-3806   	; 0x1ec <Enter_Kernel>
    10ca:	08 95       	ret

000010cc <Task_Yield>:
    10cc:	80 91 1c 16 	lds	r24, 0x161C
    10d0:	90 91 1d 16 	lds	r25, 0x161D
    10d4:	89 2b       	or	r24, r25
    10d6:	21 f4       	brne	.+8      	; 0x10e0 <Task_Yield+0x14>
    10d8:	83 e0       	ldi	r24, 0x03	; 3
    10da:	80 93 20 16 	sts	0x1620, r24
    10de:	08 95       	ret
    10e0:	f8 94       	cli
    10e2:	e0 91 23 16 	lds	r30, 0x1623
    10e6:	f0 91 24 16 	lds	r31, 0x1624
    10ea:	82 e0       	ldi	r24, 0x02	; 2
    10ec:	85 83       	std	Z+5, r24	; 0x05
    10ee:	7e c8       	rjmp	.-3844   	; 0x1ec <Enter_Kernel>
    10f0:	08 95       	ret

000010f2 <Mutex_Init>:
}

MUTEX Mutex_Init(void)
{
	if(KernelActive)
    10f2:	80 91 1c 16 	lds	r24, 0x161C
    10f6:	90 91 1d 16 	lds	r25, 0x161D
    10fa:	89 2b       	or	r24, r25
    10fc:	49 f0       	breq	.+18     	; 0x1110 <Mutex_Init+0x1e>
	{
		Disable_Interrupt();
    10fe:	f8 94       	cli
		Cp->request = CREATE_M;
    1100:	e0 91 23 16 	lds	r30, 0x1623
    1104:	f0 91 24 16 	lds	r31, 0x1624
    1108:	8a e0       	ldi	r24, 0x0A	; 10
    110a:	85 83       	std	Z+5, r24	; 0x05
		Enter_Kernel();
    110c:	6f d8       	rcall	.-3874   	; 0x1ec <Enter_Kernel>
    110e:	01 c0       	rjmp	.+2      	; 0x1112 <Mutex_Init+0x20>
	}
	else
		Kernel_Create_Mutex();	//Call the kernel function directly if OS hasn't start yet
    1110:	5a db       	rcall	.-2380   	; 0x7c6 <Kernel_Create_Mutex>
	
	
	//Return zero as Mutex ID if the mutex creation process gave errors. Note that the smallest valid mutex ID is 1
	if (err == MAX_MUTEX_ERR)
    1112:	80 91 20 16 	lds	r24, 0x1620
    1116:	8c 30       	cpi	r24, 0x0C	; 12
    1118:	29 f0       	breq	.+10     	; 0x1124 <Mutex_Init+0x32>
	
	#ifdef DEBUG
	printf("Created Mutex: %d\n", Last_MutexID);
	#endif
	
	return Last_MutexID;
    111a:	80 91 25 16 	lds	r24, 0x1625
    111e:	90 91 26 16 	lds	r25, 0x1626
    1122:	08 95       	ret
		Kernel_Create_Mutex();	//Call the kernel function directly if OS hasn't start yet
	
	
	//Return zero as Mutex ID if the mutex creation process gave errors. Note that the smallest valid mutex ID is 1
	if (err == MAX_MUTEX_ERR)
	return 0;
    1124:	80 e0       	ldi	r24, 0x00	; 0
    1126:	90 e0       	ldi	r25, 0x00	; 0
	#ifdef DEBUG
	printf("Created Mutex: %d\n", Last_MutexID);
	#endif
	
	return Last_MutexID;
}
    1128:	08 95       	ret

0000112a <Mutex_Lock>:

void Mutex_Lock(MUTEX m)
{
	if(!KernelActive){
    112a:	20 91 1c 16 	lds	r18, 0x161C
    112e:	30 91 1d 16 	lds	r19, 0x161D
    1132:	23 2b       	or	r18, r19
    1134:	21 f4       	brne	.+8      	; 0x113e <Mutex_Lock+0x14>
		err = KERNEL_INACTIVE_ERR;
    1136:	83 e0       	ldi	r24, 0x03	; 3
    1138:	80 93 20 16 	sts	0x1620, r24
		return;
    113c:	08 95       	ret
	}
	Disable_Interrupt();
    113e:	f8 94       	cli
	
	Cp->request = LOCK_M;
    1140:	e0 91 23 16 	lds	r30, 0x1623
    1144:	f0 91 24 16 	lds	r31, 0x1624
    1148:	2b e0       	ldi	r18, 0x0B	; 11
    114a:	25 83       	std	Z+5, r18	; 0x05
	Cp->request_arg = m;
    114c:	97 83       	std	Z+7, r25	; 0x07
    114e:	86 83       	std	Z+6, r24	; 0x06
	Enter_Kernel();
    1150:	4d c8       	rjmp	.-3942   	; 0x1ec <Enter_Kernel>
    1152:	08 95       	ret

00001154 <Mutex_Unlock>:
}

void Mutex_Unlock(MUTEX m)
{
	if(!KernelActive){
    1154:	20 91 1c 16 	lds	r18, 0x161C
    1158:	30 91 1d 16 	lds	r19, 0x161D
    115c:	23 2b       	or	r18, r19
    115e:	21 f4       	brne	.+8      	; 0x1168 <Mutex_Unlock+0x14>
		err = KERNEL_INACTIVE_ERR;
    1160:	83 e0       	ldi	r24, 0x03	; 3
    1162:	80 93 20 16 	sts	0x1620, r24
		return;
    1166:	08 95       	ret
	}
	Disable_Interrupt();
    1168:	f8 94       	cli
	
	Cp->request = UNLOCK_M;
    116a:	e0 91 23 16 	lds	r30, 0x1623
    116e:	f0 91 24 16 	lds	r31, 0x1624
    1172:	2c e0       	ldi	r18, 0x0C	; 12
    1174:	25 83       	std	Z+5, r18	; 0x05
	Cp->request_arg = m;
    1176:	97 83       	std	Z+7, r25	; 0x07
    1178:	86 83       	std	Z+6, r24	; 0x06
	Enter_Kernel();
    117a:	38 c8       	rjmp	.-3984   	; 0x1ec <Enter_Kernel>
    117c:	08 95       	ret

0000117e <main>:
	uart_init();
	uart_setredir();
	printf("STDOUT->UART!\n");
   #endif  
   
   a_main();
    117e:	3b c0       	rjmp	.+118    	; 0x11f6 <a_main>
    1180:	08 95       	ret

00001182 <task_r>:

MUTEX mut;

void task_r()
{
	PORTB |= (1<<PB2);	//pin 51 on
    1182:	2a 9a       	sbi	0x05, 2	; 5
	PORTB &= ~(1<<PB2);	//pin 51 off
    1184:	2a 98       	cbi	0x05, 2	; 5
	Task_Terminate();
    1186:	8f cf       	rjmp	.-226    	; 0x10a6 <Task_Terminate>
    1188:	08 95       	ret

0000118a <task_q>:
}

void task_q()
{
	//printf("q: hello, gonna create R\n");
	PORTB |= (1<<PB1);	//pin 52 on
    118a:	29 9a       	sbi	0x05, 1	; 5
	PORTB &= ~(1<<PB1);	//pin 52 off
    118c:	29 98       	cbi	0x05, 1	; 5
	Task_Create(task_r, 2, 0);
    118e:	40 e0       	ldi	r20, 0x00	; 0
    1190:	50 e0       	ldi	r21, 0x00	; 0
    1192:	62 e0       	ldi	r22, 0x02	; 2
    1194:	81 ec       	ldi	r24, 0xC1	; 193
    1196:	98 e0       	ldi	r25, 0x08	; 8
    1198:	63 df       	rcall	.-314    	; 0x1060 <Task_Create>
	//printf("q: gonna try to lock mut\n");
	PORTB |= (1<<PB1);	//pin 52 on
    119a:	29 9a       	sbi	0x05, 1	; 5
	PORTB &= ~(1<<PB1);	//pin 52 off
    119c:	29 98       	cbi	0x05, 1	; 5
	Mutex_Lock(mut);
    119e:	80 91 29 16 	lds	r24, 0x1629
    11a2:	90 91 2a 16 	lds	r25, 0x162A
    11a6:	c1 df       	rcall	.-126    	; 0x112a <Mutex_Lock>
	PORTB |= (1<<PB1);	//pin 52 on
    11a8:	29 9a       	sbi	0x05, 1	; 5
	PORTB &= ~(1<<PB1);	//pin 52 off
    11aa:	29 98       	cbi	0x05, 1	; 5
	//printf("q: I got into the mutex yeah! But I will let it go\n");
	Mutex_Lock(mut);
    11ac:	80 91 29 16 	lds	r24, 0x1629
    11b0:	90 91 2a 16 	lds	r25, 0x162A
    11b4:	ba df       	rcall	.-140    	; 0x112a <Mutex_Lock>
	PORTB |= (1<<PB1);	//pin 52 on
    11b6:	29 9a       	sbi	0x05, 1	; 5
	PORTB &= ~(1<<PB1);	//pin 52 off
    11b8:	29 98       	cbi	0x05, 1	; 5
	//printf("q: I am gonna die, good bye world\n");
	Task_Terminate();
    11ba:	75 cf       	rjmp	.-278    	; 0x10a6 <Task_Terminate>
    11bc:	08 95       	ret

000011be <task_p>:
}

void task_p()
{
	//printf("p:hello, gonna lock mut\n");
	PORTB |= (1<<PB3);	//pin 50 on
    11be:	2b 9a       	sbi	0x05, 3	; 5
	PORTB &= ~(1<<PB3);	//pin 50 off
    11c0:	2b 98       	cbi	0x05, 3	; 5
	Mutex_Lock(mut);
    11c2:	80 91 29 16 	lds	r24, 0x1629
    11c6:	90 91 2a 16 	lds	r25, 0x162A
    11ca:	af df       	rcall	.-162    	; 0x112a <Mutex_Lock>
	//printf("p: gonna create q\n");
	PORTB |= (1<<PB3);	//pin 50 on
    11cc:	2b 9a       	sbi	0x05, 3	; 5
	PORTB &= ~(1<<PB3);	//pin 50 off
    11ce:	2b 98       	cbi	0x05, 3	; 5
	Task_Create(task_q, 1, 0);
    11d0:	40 e0       	ldi	r20, 0x00	; 0
    11d2:	50 e0       	ldi	r21, 0x00	; 0
    11d4:	61 e0       	ldi	r22, 0x01	; 1
    11d6:	85 ec       	ldi	r24, 0xC5	; 197
    11d8:	98 e0       	ldi	r25, 0x08	; 8
    11da:	42 df       	rcall	.-380    	; 0x1060 <Task_Create>
	Task_Yield();
    11dc:	77 df       	rcall	.-274    	; 0x10cc <Task_Yield>
	PORTB |= (1<<PB3);	//pin 50 on
    11de:	2b 9a       	sbi	0x05, 3	; 5
	PORTB &= ~(1<<PB3);	//pin 50 off
    11e0:	2b 98       	cbi	0x05, 3	; 5
	Mutex_Unlock(mut);
    11e2:	80 91 29 16 	lds	r24, 0x1629
    11e6:	90 91 2a 16 	lds	r25, 0x162A
    11ea:	b4 df       	rcall	.-152    	; 0x1154 <Mutex_Unlock>
	Task_Yield();
    11ec:	6f df       	rcall	.-290    	; 0x10cc <Task_Yield>
	PORTB |= (1<<PB3);	//pin 50 on
    11ee:	2b 9a       	sbi	0x05, 3	; 5
	PORTB &= ~(1<<PB3);	//pin 50 off
    11f0:	2b 98       	cbi	0x05, 3	; 5
	Task_Terminate();
    11f2:	59 cf       	rjmp	.-334    	; 0x10a6 <Task_Terminate>
    11f4:	08 95       	ret

000011f6 <a_main>:
}

void a_main() {
	//initialize pins
	DDRB |= (1<<PB1);	//pin 52
    11f6:	21 9a       	sbi	0x04, 1	; 4
	DDRB |= (1<<PB2);	//pin 51
    11f8:	22 9a       	sbi	0x04, 2	; 4
	DDRB |= (1<<PB3);	//pin 50
    11fa:	23 9a       	sbi	0x04, 3	; 4
	
	OS_Init();
    11fc:	84 db       	rcall	.-2296   	; 0x906 <OS_Init>
	mut = Mutex_Init();
    11fe:	79 df       	rcall	.-270    	; 0x10f2 <Mutex_Init>
    1200:	90 93 2a 16 	sts	0x162A, r25
    1204:	80 93 29 16 	sts	0x1629, r24
	Task_Create(task_p, 3, 0);
    1208:	40 e0       	ldi	r20, 0x00	; 0
    120a:	50 e0       	ldi	r21, 0x00	; 0
    120c:	63 e0       	ldi	r22, 0x03	; 3
    120e:	8f ed       	ldi	r24, 0xDF	; 223
    1210:	98 e0       	ldi	r25, 0x08	; 8
    1212:	26 df       	rcall	.-436    	; 0x1060 <Task_Create>
	OS_Start();
    1214:	ea cb       	rjmp	.-2092   	; 0x9ea <OS_Start>
    1216:	08 95       	ret

00001218 <__tablejump2__>:
    1218:	ee 0f       	add	r30, r30
    121a:	ff 1f       	adc	r31, r31
    121c:	88 1f       	adc	r24, r24
    121e:	8b bf       	out	0x3b, r24	; 59
    1220:	07 90       	elpm	r0, Z+
    1222:	f6 91       	elpm	r31, Z
    1224:	e0 2d       	mov	r30, r0
    1226:	19 94       	eijmp

00001228 <puts>:
    1228:	0f 93       	push	r16
    122a:	1f 93       	push	r17
    122c:	cf 93       	push	r28
    122e:	df 93       	push	r29
    1230:	e0 91 2d 16 	lds	r30, 0x162D
    1234:	f0 91 2e 16 	lds	r31, 0x162E
    1238:	23 81       	ldd	r18, Z+3	; 0x03
    123a:	21 ff       	sbrs	r18, 1
    123c:	1b c0       	rjmp	.+54     	; 0x1274 <puts+0x4c>
    123e:	8c 01       	movw	r16, r24
    1240:	d0 e0       	ldi	r29, 0x00	; 0
    1242:	c0 e0       	ldi	r28, 0x00	; 0
    1244:	f8 01       	movw	r30, r16
    1246:	81 91       	ld	r24, Z+
    1248:	8f 01       	movw	r16, r30
    124a:	60 91 2d 16 	lds	r22, 0x162D
    124e:	70 91 2e 16 	lds	r23, 0x162E
    1252:	db 01       	movw	r26, r22
    1254:	18 96       	adiw	r26, 0x08	; 8
    1256:	ed 91       	ld	r30, X+
    1258:	fc 91       	ld	r31, X
    125a:	19 97       	sbiw	r26, 0x09	; 9
    125c:	88 23       	and	r24, r24
    125e:	31 f0       	breq	.+12     	; 0x126c <puts+0x44>
    1260:	19 95       	eicall
    1262:	89 2b       	or	r24, r25
    1264:	79 f3       	breq	.-34     	; 0x1244 <puts+0x1c>
    1266:	df ef       	ldi	r29, 0xFF	; 255
    1268:	cf ef       	ldi	r28, 0xFF	; 255
    126a:	ec cf       	rjmp	.-40     	; 0x1244 <puts+0x1c>
    126c:	8a e0       	ldi	r24, 0x0A	; 10
    126e:	19 95       	eicall
    1270:	89 2b       	or	r24, r25
    1272:	19 f0       	breq	.+6      	; 0x127a <puts+0x52>
    1274:	8f ef       	ldi	r24, 0xFF	; 255
    1276:	9f ef       	ldi	r25, 0xFF	; 255
    1278:	02 c0       	rjmp	.+4      	; 0x127e <puts+0x56>
    127a:	8d 2f       	mov	r24, r29
    127c:	9c 2f       	mov	r25, r28
    127e:	df 91       	pop	r29
    1280:	cf 91       	pop	r28
    1282:	1f 91       	pop	r17
    1284:	0f 91       	pop	r16
    1286:	08 95       	ret

00001288 <_exit>:
    1288:	f8 94       	cli

0000128a <__stop_program>:
    128a:	ff cf       	rjmp	.-2      	; 0x128a <__stop_program>
